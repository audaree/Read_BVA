{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eddfcd8f",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Julia program to read a selected .BVA file and display 30-minute time series plots\n",
    "## JW October 2022\n",
    "#using ContinuousWavelets \n",
    "using ContinuousWavelets, CSV\n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using FFTW\n",
    "##using Gtk\n",
    "using LaTeXStrings\n",
    "using NativeFileDialog\n",
    "using Plots\n",
    "using Printf\n",
    "using Statistics #, StatsPlots\n",
    "#using Suppressor: @suppress\n",
    "using Wavelets\n",
    "\n",
    "##import Pkg; Pkg.add(\"Suppressor\")\n",
    "## See https://github.com/JuliaIO/Suppressor.jl\n",
    "##using Suppressor: @suppress\n",
    "\n",
    "include(\"./read_BVA_processing_tools.jl\")\n",
    "include(\"./read_BVA_plotting_tools.jl\")\n",
    "\n",
    "function handle_gaps(df)\n",
    "################################################    \n",
    "# a function to identify where gaps found in sequence numbers\n",
    "#    where gaps occur a dummy record is inserted into the df\n",
    "#    and both Status1 and Status2 are flagged with a '!' \n",
    "    \n",
    "    nums = []\n",
    "\n",
    "    # Convert sequence number value from Hex to Integer\n",
    "    for i in 1:nrow(df)\n",
    "        str = df.Sequence[i]\n",
    "        push!(nums,parse(Int, str[1], base=16) * 16 + parse(Int, str[2], base=16))\n",
    "    end\n",
    "\n",
    "    # Determine number of gaps in df rows\n",
    "    counter = diff(nums)\n",
    "    gaps = findall(counter.<1)\n",
    "    counter[gaps] .+= 256;\n",
    "\n",
    "    # now find where a counter is > 1 indicating number of gaps in transmission\n",
    "    gaps = findall(counter.>1)\n",
    "    ll = length(gaps)\n",
    "        \n",
    "    if ll > 0\n",
    "        \n",
    "        println(cumsum(gaps),\" found in file!\")\n",
    "        println(\"File contains \",nrow(df),\" records\")\n",
    "    \n",
    "\n",
    "##    df1 = deepcopy(df)\n",
    "\n",
    "        # need to work through the gaps in reverse order in order to preserve row numbers\n",
    "        for i in ll:-1:1\n",
    "            # for each gap, get sequence number of last valid row\n",
    "            sequence_number = df[gaps[i],:].Sequence\n",
    "\n",
    "            # for number of gaps, insert \"FFF\" values into df and '!' into the status indicators\n",
    "            for j in 1:counter[gaps[i]]-1\n",
    "\n",
    "                sequence_number_hex = uppercase(string((parse(Int, sequence_number[1], base=16) * 16 + parse(Int, sequence_number[2], base=16)) + j, base=16, pad=2))\n",
    "        ##        println(i,' ',j,' ',gaps[i]+j,' ',counter[gaps[i]],' ',sequence_number,' ',sequence_number_hex,' ',\"!\",' ',\"FFFFFFFFFFFFFFFFFF\",' ',\"!\",' ',\"FFFFFF\")\n",
    "                insert!(df, gaps[i]+j, [sequence_number_hex, '!', \"FFFFFFFFFFFFFFFFFF\", '!', \"FFFFFF\"])\n",
    "\n",
    "            end\n",
    "                \n",
    "        end\n",
    "\n",
    "        println(\"File now contains \",nrow(df),\" records\")\n",
    "                \n",
    "    else\n",
    "                \n",
    "        println(\"No gaps in record\")\n",
    "                \n",
    "    end\n",
    "\n",
    "    return (df)\n",
    "        \n",
    "    end    # handle_gaps()\n",
    "    \n",
    "\n",
    "function string2hex(str)\n",
    "################################################    \n",
    "    parsed_val = (parse(Int, str[1], base=16) * 16 + parse(Int, str[2], base=16));\n",
    "    if parsed_val == 0\n",
    "        hex = 0x00\n",
    "    else\n",
    "        hex = [(parsed_val>>((i-1)<<3))%UInt8 for i in 1:sizeof(parsed_val)-leading_zeros(parsed_val)>>3][1]\n",
    "    end\n",
    "    \n",
    "    return(hex)\n",
    "    \n",
    "    end    # string2hex()\n",
    "\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           START OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "# Select a HVA or BVA file\n",
    "##infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Bris\\\\BVA\\\\\", filterlist=\"HVA,BVA;hva,bva\");\n",
    "infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Brisbane_offshore\\\\\", filterlist=\"HVA,BVA;hva,bva\");\n",
    "println(\"Selected \",infil)\n",
    "flush(stdout)\n",
    "\n",
    "if uppercase(split(infil, \".\")[end]) == \"HVA\"\n",
    "    \n",
    "#    df = DataFrame(CSV.File(infil,header=0, delim=\",-\"));\n",
    "#    rename!(df,[:Sequence,:Data, :Packet]);\n",
    "    \n",
    "    # read data from file to df\n",
    "    df = DataFrame(CSV.File(infil,header=0))\n",
    "\n",
    "    # add column names to df as shown in DWTP Section 2.1 pp 18-19 - Status1; Data; Status2; Packet\n",
    "    transform!(df, :Column2 => ByRow(x -> x[1]) => :Status1)\n",
    "    transform!(df, :Column2 => ByRow(x -> x[2:19]) => :Data)\n",
    "    transform!(df, :Column3 => ByRow(x -> x[1]) => :Status2)\n",
    "    transform!(df, :Column3 => ByRow(x -> x[2:7]) => :Packet)\n",
    "\n",
    "    rename!(df,:Column1 => :Sequence)\n",
    "    DataFrames.select!(df, Not([:Column2, :Column3]))\n",
    "            \n",
    "    df1 = deepcopy(df)\n",
    "    df = handle_gaps(df)    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "    # identify rows where channel not received OK ( see DWTP 2.1 pp. 18-19)\n",
    "    bad = findall(df[!,:Status1] .== '!')\n",
    "    if !isempty(bad)\n",
    "        println(length(bad),\" unrecoverable records found!\")\n",
    "    else\n",
    "        println(\"No unrecoverable records found!\")\n",
    "    end \n",
    "\n",
    "###    delete!(df, bad) # drop rows where channel is damaged beyond repair\n",
    "    suspect = findall(df[!,:Status1] .== '=') # flag rows where channel is damaged but has been repaired successfully\n",
    "    if !isempty(suspect)\n",
    "        println(length(suspect),\" damaged records found that have been repaired successfully!\")\n",
    "    else\n",
    "        println(\"All records received OK!\")\n",
    "    end \n",
    "\n",
    "    # create a Packet vector of hex values\n",
    "    packet = []\n",
    "    \n",
    "    for i in 1:length(df.Packet)\n",
    "        push!(packet,string2hex(SubString(df.Packet[i],1,2)))\n",
    "        push!(packet,string2hex(SubString(df.Packet[i],3,4)))\n",
    "        push!(packet,string2hex(SubString(df.Packet[i],5,6)))\n",
    "    end  \n",
    "    \n",
    "    # create a Data vector of hex values\n",
    "    Data = lowercase.(df.Data)\n",
    "    \n",
    "elseif uppercase(split(infil, \".\")[end]) == \"BVA\"\n",
    "    \n",
    "    #Change the type-interpretation of the binary file data to unsigned integer\n",
    "    println(\"Reading BINARY data from \",infil)\n",
    "    data = reinterpret(UInt8, read(infil));\n",
    "\n",
    "    # turn the data vector into a matrix of 12 values matching hexadecimal bytes - see DWTP 2.1 p.18\n",
    "    cols = 12\n",
    "    rows = Int(length(data) / cols)\n",
    "    mat = reshape(view(data, :), cols, :);\n",
    "\n",
    "    # Interleave last 4 matrix columns to form packet vector\n",
    "    ## based on mschauer @ https://discourse.julialang.org/t/combining-two-arrays-with-alternating-elements/15498/2\n",
    "    packet = collect(Iterators.flatten(zip(mat[10,:],mat[11,:],mat[12,:])));\n",
    "    \n",
    "    ## get data for the Heave, North, and West displacements\n",
    "    Data = []\n",
    "\n",
    "    # Convert binary data to hexidecimal vectors\n",
    "    j = 0\n",
    "    println(\"Building displacements vectors - this takes a while!\")\n",
    "    while true\n",
    "\n",
    "        try\n",
    "            aa = []\n",
    "\n",
    "            for i = j*12+1:j*12+12\n",
    "                push!(aa,string(data[i], base = 16, pad = 2))\n",
    "            end\n",
    "\n",
    "            push!(Data,join(aa)[1:18])\n",
    "\n",
    "        catch\n",
    "\n",
    "            # escape if something is amiss        \n",
    "            break\n",
    "\n",
    "        end\n",
    "        j = j+1\n",
    "\n",
    "    end\n",
    "\n",
    "else\n",
    "    println(\"Not able to read this file type at present\")\n",
    "    exit()\n",
    "end\n",
    "\n",
    "# find all occurrences of 0x7e in packet vector\n",
    "aa = findall(x->x.==0x7e, vec(packet));\n",
    "\n",
    "# Create the df's to hold the processed data and setup their column structure\n",
    "f20_vals = []; f21_vals = []; f23_vals = []; f25_vals = []; f26_vals = []; f28_vals = []; f29_vals = [];\n",
    "    f80_vals = []; f81_vals = []; f82_vals = []; fc1_vals = []; fc3_vals = []\n",
    "\n",
    "f20_df = DataFrame(Date = [], Segments = [], Smax = [])\n",
    "for i in 0:99\n",
    "    col_name = \"S$i\"\n",
    "    f20_df[!,col_name] = []\n",
    "end\n",
    "f21_df = DataFrame(Date = [], Segments = [])\n",
    "\n",
    "for i in 0:99\n",
    "    col_name = \"Dir$i\"\n",
    "    f21_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"Spread$i\"\n",
    "    f21_df[!,col_name] = []\n",
    "end\n",
    "f23_df = DataFrame(Date = [], Segments = [], Match_vector = [], Sample_number = [])\n",
    "f25_df = DataFrame(Date = [], Segments = [], Hs = [], Ti = [], Te = [], T1 = [], Tz = [], T3 = [], \n",
    "    Tc = [], Rp = [], Tp = [], Smax = [], Theta_p = [], σ_p = [])\n",
    "f26_df = DataFrame(Date = [], Hmax = [], Thmax = [], Tmax = [], Htmax = [], Havg = [], Tavg = [], \n",
    "    Hsrms = [], Nw = [], Nc = [], Epsilon = [], Coverage = [])\n",
    "f28_df = DataFrame(Date = [], Segments = [])\n",
    "for i in 0:99\n",
    "    col_name = \"m2_$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"n2_$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"k$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "f29_df = DataFrame(Date = [], Coverage = [], Nw = [], Epsilon = [], Hmax = [], THmax = [], H10 = [], \n",
    "    TH10 = [], H3 = [], TH3 = [], Havg = [], Tavg = [])\n",
    "for i in 0:22\n",
    "    col_name = \"Hq$i\"\n",
    "    f29_df[!,col_name] = []\n",
    "end\n",
    "f80_df = DataFrame(Date = [], Latitude = [], Longitude = [])\n",
    "f81_df = DataFrame(Date = [], SST = [])\n",
    "f82_df = DataFrame(Date = [], Firmware_Version = [], Speed = [], Direction = [], SST = [])\n",
    "fc1_df = DataFrame(Date = [], Firmware = [], Hatch_uid = [], Hull_uid = [], Uptime = [], \n",
    "    Battery_energy = [], Boostcaps_energy = [],\n",
    "    Hatch_temp = [], Battery_voltage = [], Batteries_per_section = [], Battery_section_number = [], \n",
    "    Initial_battery_energy = [], Ov = [], Cv = [], Ox = [], Oy = [], Cx = [], Cy = [], μ₀ = [], \n",
    "    σ₀ = [], μᵢ = [], σᵢ = [], μₕ = [], σh = [], Cpitch = [], Croll = [], Tensor = [])\n",
    "fc3_df = DataFrame(Date = [], Battery_life = [])\n",
    "\n",
    "# determine number of records\n",
    "max_val = length(aa)-1\n",
    "\n",
    "# Decode the packet data to messages\n",
    "# refer to Section 2.1.2 Decoding the packet data to messages p. 20\n",
    "messages = []\n",
    "\n",
    "println(\"Processing the Packet vectors\")\n",
    "for i in 1:max_val\n",
    "    # determine packet length\n",
    "    first = aa[i]+1\n",
    "    last = aa[i+1]\n",
    "            \n",
    "    list1 = []; list2 = []\n",
    "    \n",
    "    if (last-first > 1)\n",
    "        global decoded = []\n",
    "        decoded = packet[first:last-1]\n",
    "        decode_length = length(decoded)\n",
    "                \n",
    "        bb = findall(x->x.==0x7d, vec(decoded));\n",
    "            \n",
    "        if bb != []\n",
    "\n",
    "            # do an xor of elements with 0x7d\n",
    "            for ii in bb\n",
    "                if ii<(last-first)\n",
    "                    decoded[ii+1] = decoded[ii+1] ⊻ 0x20 # set the xor value as 0x20 vide 2.1.2 p.20\n",
    "                end\n",
    "            end\n",
    "\n",
    "            # remove the 0x7d\n",
    "            deleteat!(decoded::Vector, bb)\n",
    "            decode_length = length(decoded)\n",
    "\n",
    "        end\n",
    "\n",
    "##        println(string(decoded[2], base=16, pad=2),' ',length(decoded))\n",
    "\n",
    "        # look for vectors of the spectrum synchronisation message (0xF23)\n",
    "        if decoded[2] == 0x20\n",
    "                    \n",
    "            if decode_length !=161\n",
    "                println(\"Alert 0xF20 message length is \",decode_length,\" but should be 161\")\n",
    "            else           \n",
    "                heave_spectrum = []\n",
    "                append!(f20_vals,decoded)\n",
    "                timestamp,segments,smax,heave_spectrum = process_f20(decoded,heave_spectrum)         \n",
    "                list_1 = [timestamp,segments,smax]\n",
    "                push!(f20_df, [list_1; heave_spectrum])\n",
    "            end\n",
    "            \n",
    "        elseif decoded[2] == 0x21\n",
    "                    \n",
    "            if decode_length !=309\n",
    "                println(\"Alert 0xF21 message length is \",decode_length,\" but should be 309\")\n",
    "            else\n",
    "\n",
    "                global direction = []\n",
    "                global spread = []\n",
    "                append!(f21_vals,decoded)\n",
    "                timestamp,segments,direction,spread = process_f21(decoded,direction,spread)\n",
    "\n",
    "                list1 = [timestamp,segments]\n",
    "                list2 = [direction; spread]\n",
    "\n",
    "                push!(f21_df, [list1; list2])\n",
    "\n",
    "            end\n",
    "                    \n",
    "        elseif decoded[2] == 0x23\n",
    "                  \n",
    "            if decode_length !=22\n",
    "                println(\"Alert 0xF23 message length is \",decode_length,\" but should be 22\")\n",
    "            else\n",
    "\n",
    "                append!(f23_vals,decoded)\n",
    "                timestamp,segments_used,match_vector,sample_number = process_f23(decoded)\n",
    "                push!(f23_df, [timestamp,segments_used,match_vector,sample_number])\n",
    "\n",
    "            end\n",
    "\n",
    "        elseif decoded[2] == 0x25\n",
    "\n",
    "            if decode_length !=27\n",
    "                println(\"Alert 0xF25 message length is \",decode_length,\" but should be 27\")\n",
    "            else\n",
    "\n",
    "                append!(f25_vals,decoded)\n",
    "                timestamp,segments,hs,ti,te,t1,tz,t3,tc,rp,tp,smax,theta_p,σ_p = process_f25(decoded)\n",
    "                push!(f25_df, [timestamp,segments,hs,ti,te,t1,tz,t3,tc,rp,tp,smax,theta_p,σ_p])\n",
    "            end\n",
    "\n",
    "            elseif decoded[2] == 0x26\n",
    "\n",
    "            if decode_length !=25\n",
    "                println(\"Alert 0xF26 message length is \",decode_length,\" but should be 25\")\n",
    "            else                    \n",
    "\n",
    "                append!(f26_vals,decoded)\n",
    "                timestamp,hmax,thmax,tmax,htmax,havg,tavg,hsrms,nw,nc,epsilon,coverage = process_f26(decoded)\n",
    "                push!(f26_df, [timestamp,hmax,thmax,tmax,htmax,havg,tavg,hsrms,nw,nc,epsilon,coverage])\n",
    "            end\n",
    "\n",
    "        elseif decoded[2] == 0x28\n",
    "\n",
    "            if decode_length !=459\n",
    "                println(\"Alert 0xF28 message length is \",decode_length,\" but should be 459\")\n",
    "            else                    \n",
    "            \n",
    "                m2 = []\n",
    "                n2 = []\n",
    "                k = []\n",
    "                append!(f28_vals,decoded)\n",
    "                timestamp,segments,m2,n2,k = process_f28(decoded,m2,n2,k)\n",
    "\n",
    "                global list1 = [timestamp,segments]\n",
    "                global list2 = [m2; n2; k]\n",
    "\n",
    "                push!(f28_df, [list1; list2])\n",
    "            end\n",
    "            \n",
    "        elseif decoded[2] == 0x29\n",
    "\n",
    "            if decode_length !=59\n",
    "                println(\"Alert 0xF29 message length is \",decode_length,\" but should be 59\")\n",
    "            else                 \n",
    "                    \n",
    "                hq = []\n",
    "                append!(f29_vals,decoded)\n",
    "                timestamp,coverage,nw,epsilon,hmax,thmax,h10,th10,h3,th3,havg,tavg,hq = process_f29(decoded,hq)         \n",
    "                list_1 = [timestamp,coverage,nw,epsilon,hmax,thmax,h10,th10,h3,th3,havg,tavg]\n",
    "                push!(f29_df, [list_1; hq])\n",
    "            end\n",
    "        elseif decoded[2] == 0x80\n",
    "\n",
    "            if decode_length !=14\n",
    "                println(\"Alert 0xF80 message length is \",decode_length,\" but should be 14\")\n",
    "            else                 \n",
    "            \n",
    "                append!(f80_vals,decoded)\n",
    "                timestamp,latitude,longitude = process_f80(decoded)\n",
    "                push!(f80_df, [timestamp,latitude,longitude])\n",
    "            end         \n",
    "        elseif decoded[2] == 0x81\n",
    "\n",
    "            if decode_length !=10\n",
    "                println(\"Alert 0xF81 message length is \",decode_length,\" but should be 10\")\n",
    "            else                 \n",
    "            \n",
    "                append!(f81_vals,decoded)\n",
    "                timestamp,sst = process_f81(decoded)\n",
    "                push!(f81_df, [timestamp,sst])\n",
    "            end\n",
    "        elseif decoded[2] == 0x82\n",
    "\n",
    "            if decode_length !=29\n",
    "                println(\"Alert 0xF82 message length is \",decode_length,\" but should be 29\")\n",
    "            else                 \n",
    "            \n",
    "                append!(f82_vals,decoded)\n",
    "                timestamp,firmware_version,speed,direction,sst = process_f82(decoded)\n",
    "                push!(f82_df, [timestamp,firmware_version,speed,direction,sst])\n",
    "\n",
    "            end\n",
    "        elseif decoded[2] == 0xc1\n",
    "\n",
    "            if decode_length !=67\n",
    "                println(\"Alert 0xFC1 message length is \",decode_length,\" but should be 67\")\n",
    "            else                 \n",
    "            \n",
    "                append!(fc1_vals,decoded)\n",
    "                timestamp,firmware,hatch_uid,hull_uid,uptime,battery_energy,boostcaps_energy,hatch_temp,battery_voltage,batteries_per_section,\n",
    "                    battery_section_number,initial_battery_energy,ov,cv,ox,oy,cx,cy,μ₀,σ₀,μᵢ,σᵢ,μₕ,σh,cpitch,croll,tensor = process_fc1(decoded)   \n",
    "\n",
    "                push!(fc1_df, [timestamp,firmware,hatch_uid,hull_uid,uptime,battery_energy,boostcaps_energy,hatch_temp,battery_voltage,batteries_per_section,\n",
    "                    battery_section_number,initial_battery_energy,ov,cv,ox,oy,cx,cy,μ₀,σ₀,μᵢ,σᵢ,μₕ,σh,cpitch,croll,tensor])\n",
    "            end\n",
    "        elseif decoded[2] == 0xc3\n",
    "\n",
    "            if decode_length !=9\n",
    "                println(\"Alert 0xFC3 message length is \",decode_length,\" but should be 9\")\n",
    "            else                 \n",
    "            \n",
    "                append!(fc3_vals,decoded)\n",
    "                timestamp,ble = process_fc3(decoded)\n",
    "                push!(fc3_df, [timestamp,ble])\n",
    "\n",
    "            end\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "# remove duplicates from dataframes\n",
    "f20_df = unique(f20_df)\n",
    "f21_df = unique(f21_df)\n",
    "f23_df = unique(f23_df)\n",
    "f25_df = unique(f25_df)\n",
    "f26_df = unique(f26_df)    \n",
    "f28_df = unique(f28_df)\n",
    "f29_df = unique(f29_df)\n",
    "f80_df = unique(f80_df)\n",
    "f81_df = unique(f81_df)\n",
    "f82_df = unique(f82_df)\n",
    "fc1_df = unique(fc1_df)\n",
    "fc3_df = unique(fc3_df)\n",
    "\n",
    "println(\"All file data read!\")\n",
    "println(\"Preparing to plot data\")\n",
    "flush(stdout)\n",
    "    \n",
    "# remove those vectors from F23 df that are not located in the Data vector df\n",
    "f23_df[!,\"Data_vector\"] = [findfirst(x->x==i, Data) for i in f23_df.Match_vector];\n",
    "\n",
    "# Do time-series plot of available data\n",
    "plot_f29(f29_df)\n",
    "\n",
    "# Plot current speed and direction\n",
    "plot_f82(f82_df)\n",
    "\n",
    "println(\"Select date from menu for more plots\")\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           END OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f1ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Locate bad WSE data\n",
    "bad_wse = findall(df.Status1.=='!')\n",
    "\n",
    "# Locate bad Packet data\n",
    "bad_packet = findall(df.Status2.=='!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f553f",
   "metadata": {},
   "source": [
    "## Do Lagrangian plot of currents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Haversine\n",
    "# see https://juliahub.com/ui/Packages/Haversine/1CvkY/1.1.0\n",
    "\n",
    "# find closest Timestamp in 0xF82 to 0xF80 and use the λ and ϕ of this point as origin\n",
    "start_point = findmin(abs.(f82_df.Date.-f80_df.Date[1]))[2]\n",
    "\n",
    "latitudes = []; longitudes = []\n",
    "\n",
    "p = GeoLocation(λ=f80_df.Longitude[start_point], ϕ= f80_df.Latitude[start_point])\n",
    "\n",
    "push!(longitudes, p.λ)\n",
    "push!(latitudes, p.ϕ)\n",
    "\n",
    "for i in 2:nrow(f82_df)\n",
    "    \n",
    "    θ = f82_df.Direction[i-1]\n",
    "    d = f82_df.Speed[i-1] * 600\n",
    "\n",
    "    p = HaversineDestination(p, θ, d)\n",
    "    \n",
    "    push!(longitudes, p.λ)\n",
    "    push!(latitudes, p.ϕ)\n",
    "    \n",
    "    p = GeoLocation(λ=p.λ, ϕ= p.ϕ)\n",
    "    \n",
    "end\n",
    "\n",
    "f82_df.Lat = latitudes\n",
    "f82_df.Long = longitudes;\n",
    "\n",
    "# remove bad values\n",
    "f82_df = filter(:Lat => x -> !any(f -> f(x), (ismissing, isnothing, isnan)), f82_df)\n",
    "\n",
    "d2 = scatter(f82_df.Long, f82_df.Lat, marker=:circle, ms=:1, msw=:0, label=\"\", xlabel=\"Longitude (°)\", ylabel=\"Latitude (°)\", \n",
    "    leftmargin = 20Plots.mm, bottommargin = 20Plots.mm,\n",
    "    size=(800,800), aspect_ratio=:equal, framestyle = :box, title=\"Lagrangian current plot\")\n",
    "d2 = plot!(f82_df.Long, f82_df.Lat, lc=:lightblue, lw=:0.5, label=\"\", fg_legend=:transparent, bg_legend=:transparent, foreground_color_grid=\"grey\")\n",
    "d2 = scatter!([first(f82_df.Long)],[first(f82_df.Lat)], marker=:utriangle, ms=:5, mc=:green, label=\"First \"*Dates.format(first(f82_df.Date), \"yyyy-mm-dd HH:MM:SS\")*\"\\n\")\n",
    "d2 = scatter!([last(f82_df.Long)],[last(f82_df.Lat)], marker=:dtriangle, ms=:5, mc=:red, label=\"Last \"*Dates.format(last(f82_df.Date), \"yyyy-mm-dd HH:MM:SS\"))\n",
    "\n",
    "ps = plot(d2)\n",
    "\n",
    "display(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bf254",
   "metadata": {},
   "source": [
    "# Select individual records to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5a75f",
   "metadata": {},
   "source": [
    "## Select individual wave records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19169591",
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_scaleogram(heave, start_date)\n",
    "################################################\n",
    "    n=length(heave);\n",
    "    t = range(1,n/2.56,length=n);\n",
    "    \n",
    "    # time stamp each WSE\n",
    "    points = collect(0:1:length(heave)-1)/2.56\n",
    "    times = []\n",
    "\n",
    "    for i in 1:length(points)\n",
    "        push!(times,unix2datetime(datetime2unix(start_date) + points[i]))\n",
    "    end\n",
    "\n",
    "    c = wavelet(Morlet(8), β=0.75);\n",
    "    res = ContinuousWavelets.cwt(heave, c)\n",
    "\n",
    "    freqs = getMeanFreq(ContinuousWavelets.computeWavelets(n, c)[1])\n",
    "#    freqs[1] = 0\n",
    "\n",
    "    # display plots to screen\n",
    "    tm_tick = range(first(times),last(times),step=Minute(5))\n",
    "    ticks = Dates.format.(tm_tick,\"HH:MM:SS\")\n",
    "\n",
    "    p1 = heatmap(times, ((freqs.-minimum(freqs))./maximum(freqs)).*0.64, abs.(res)', c=cgrad(:Spectral, rev=true))                \n",
    "\n",
    "    for i in 0:0.1:1.28\n",
    "        hline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "    end\n",
    "\n",
    "    start_date = first(times)\n",
    "    last_date = last(times)\n",
    "\n",
    "    for i in start_date:Minute(5):last_date\n",
    "        vline!(p1, [i], lw=0.5, c=:white, label=\"\")\n",
    "    end\n",
    "\n",
    "    # Plot spectrogram over scalogram\n",
    "    nw=128;\n",
    "    spec = DSP.Periodograms.spectrogram(heave, nw, 120; fs=2.56,window=hanning);\n",
    "\n",
    "    # display plots to screen\n",
    "    tm_tick = range(first(times),last(times),step=Minute(5))\n",
    "    ticks = Dates.format.(tm_tick,\"HH:MM:SS\")\n",
    "\n",
    "    p1 = plot!(first(times) + Microsecond.(ceil.((spec.time) * 1000000)), spec.freq, DSP.Periodograms.power(spec), lw=1, c=cgrad(:Spectral, rev=true), colorbar=false) \n",
    "\n",
    "    plot_wavelet = plot(p1, \n",
    "        xlabel=\"Time\", xlim=(start_date,last_date), xticks=(tm_tick,ticks), xtickfontsize=7,\n",
    "        ylabel=\"Frequency (Hz)\", ylim=(0,0.4), ytickfontsize=8, \n",
    "        title=\"Scaleogram \" * Dates.format(start_date, \"dd/mm/yyyy HH:MM\"), framestyle = :box,\n",
    "        leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, size=(1500, 500), colorbar=false, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)\n",
    "    \n",
    "    # display plots to screen\n",
    "    display(plot_wavelet)\n",
    "    \n",
    "    return()\n",
    "    \n",
    "    end    # plot_scaleogram()\n",
    "\n",
    "    \n",
    "## Plot 30-minute records\n",
    "# create a vector of dates from the F23 df\n",
    "vector = Dates.format.(f23_df.Date, \"yyyy-mm-dd HH:MM:SS\");\n",
    "\n",
    "## Allow user to get a 30-minute record and do plots\n",
    "cb = GtkComboBoxText()\n",
    "choices = vector\n",
    "\n",
    "for choice in choices\n",
    "    push!(cb,choice)\n",
    "end\n",
    "\n",
    "set_gtk_property!(cb,:active,1)\n",
    "\n",
    "signal_connect(cb, \"changed\") do widget, others...\n",
    "\n",
    "    # get the active index\n",
    "    idx = get_gtk_property(cb, \"active\", Int) + 2\n",
    "    println(idx)\n",
    "  \n",
    "    # get the active string \n",
    "    str = Gtk.bytestring( GAccessor.active_text(cb) ) \n",
    "    \n",
    "    plot_hnw(f23_df,fc1_df,Data,idx)\n",
    "    plot_spectra(f23_df,f20_df,Data,idx)\n",
    "##    plot_2d(f23_df,Data,idx)\n",
    "##    plot_hnw_2d(f23_df,Data,idx)\n",
    "##    plot_3d(f23_df,Data,idx)\n",
    "    plot_heave_histogram(f23_df,Data,idx)\n",
    "#    plot_wavelet(f23_df,Data,idx)\n",
    "        \n",
    "    global start_date, start_val, end_val = get_start_end_dates(f23_df,idx)\n",
    "\n",
    "    # get WSEs for desired 30-minute record\n",
    "    global heave, north, west = get_hnw(Data,start_val,end_val)\n",
    "    plot_scaleogram(heave, start_date)\n",
    "\n",
    "end\n",
    "\n",
    "win = GtkWindow(\"Select Date\",200,200);\n",
    "Gtk.GAccessor.position(win, Gtk.GtkWindowPosition.CENTER);\n",
    "push!(win, cb);\n",
    "showall(win);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e520f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using CurveFit\n",
    "\n",
    "y = heave[2600:3100]\n",
    "x = 1:1:length(y)\n",
    "\n",
    "px = plot(x, y, label=\"\")\n",
    "\n",
    "fit = curve_fit(Polynomial, x, y, 30)\n",
    "yb = fit.(x) \n",
    "\n",
    "p1 = plot!(x, yb, label=\"\")\n",
    "\n",
    "px_plot = plot(px, size=(1800,600))\n",
    "\n",
    "display(px_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x, y, marker=:o, ms=:2, label=\"\", size=(1800,600))\n",
    "\n",
    "fit = curve_fit(Polynomial, x, y, 55)\n",
    "yb = y - fit.(x) \n",
    "\n",
    "plot!(x, yb, label=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d4cf4",
   "metadata": {},
   "source": [
    "### Investigate LombScargle package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1829f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LombScargle\n",
    "\n",
    "Sample_frequency = 2.56\n",
    "\n",
    "N = length(heave)\n",
    "t = collect(1:N)/Sample_frequency\n",
    "\n",
    "plan = LombScargle.plan(t, heave, normalization=:psd, fit_mean=:false, center_data=:false, samples_per_peak=:20, maximum_frequency=:0.64);\n",
    "pgram = lombscargle(plan)\n",
    "\n",
    "p = periodogram(heave; onesided=true, nfft=N, fs=2.56)\n",
    "\n",
    "ps_w = welch_pgram(heave, 512, 256; onesided=true, nfft=512, fs=Sample_frequency, window=hanning);\n",
    "f2 = freq(ps_w);\n",
    "Pden2 = power(ps_w);\n",
    "\n",
    "p1 = plot(freqpower(pgram)...,xrange=(0.0,0.64), c=:yellow, lw=:3, label=\"Lomb Scargle\\n\")\n",
    "p1 = plot!(freq(p), power(p), label=\"DSP Periodogram\\n\", c=:blue, lw=:0.5)\n",
    "p1 = plot!(f2,Pden2, label=\"DSP Welch's method\", c=:red, lw=:1)\n",
    "p2 = plot(p1, size=(1200,800), framestyle = :box, fg_legend=:transparent)\n",
    "\n",
    "display(p2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05dd07",
   "metadata": {},
   "source": [
    "### Investigate Skewness and Kurtosis calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ef035",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = skewness(heave)\n",
    "kurt = kurtosis(heave)\n",
    "\n",
    "#extrema(heave)\n",
    "\n",
    "lim=round(maximum(abs.(extrema(heave))) + 0.2; digits = 1)\n",
    "\n",
    "fit_distribution = fit_mle(Normal,heave)\n",
    "bin_vals = vcat(reverse(collect(-0.2:-0.2:-lim)),collect(0:0.2:lim))\n",
    "        \n",
    "h = histogram(heave, normalize=:false, bins=bin_vals, alpha=0.5)\n",
    "bin_count = fit(Histogram, heave, nbins=length(bins)).weights\n",
    "h = plot!(twinx(), [-lim:0.01:lim],[pdf(fit_distribution,i) for i in -lim:0.01:lim], lc=:blue, lw=:1, ls=:dash)\n",
    "\n",
    "show_normal_plot = plot(h,\n",
    "        framestyle = :box, size = (1400, 800), legend=:topleft, xlim=(first(bin_vals),last(bin_vals)),\n",
    "        leftmargin = 20Plots.mm, rightmargin = 20Plots.mm, fg_legend=:transparent)\n",
    "\n",
    "display(show_normal_plot)\n",
    "\n",
    "bins = collect(collect(fit(Histogram, heave, nbins=length(bins)).edges)[1])\n",
    "println(\"    Bins       Count\")\n",
    "for i in 1:1:length(bin_count)\n",
    "    @printf(\"%4.1f to %4.1f %7d\\n\",bins[i],bins[i+1],bin_count[i])\n",
    "end\n",
    "\n",
    "@printf(\"Skewness = %4.4f\\n\",skew)\n",
    "@printf(\"Kurtosis = %4.4f\\n\",kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e685d6c",
   "metadata": {},
   "source": [
    "## Show individual WSE's and zero-crossing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_list = 2 # <<<=== For testing only\n",
    "\n",
    "start_date, start_val, end_val = get_start_end_dates(f23_df,found_list)\n",
    "    \n",
    "# get WSEs for desired 30-minute record\n",
    "heave, north, west = get_hnw(Data,start_val,end_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_up = []; valid_zero_up = []\n",
    "\n",
    "for i in 2:length(heave)-1\n",
    "    if (heave[i]*heave[i+1] < 0 && heave[i+1] > 0) || (heave[i] == 0 && heave[i-1] < 0 && heave[i+1] > 0)\n",
    "        push!(zero_up,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "##med = median(heave)\n",
    "##stdev = std(heave)\n",
    "##stdev_3 = med + stdev*3\n",
    "\n",
    "wse_point = 1:1:length(heave)\n",
    "t = wse_point./2.56\n",
    "\n",
    "wse_1 = plot(t, heave[wse_point], lw=2, c=:blue, alpha=.5, label = \"WSE's\", fillalpha = 0.0075, fillcolor = :blue)\n",
    "wse_1 = scatter!(t, heave[wse_point], c=:white, ms=3, \n",
    "    markerstrokecolor=:blue, alpha=0.5, markerstrokewidth=0.5, label=\"WSE points\")\n",
    "wse_1 = scatter!(zero_up[1:24]./2.56, heave[zero_up[1:24]], ms=4, c=:lightgreen, xlim=(1,20), \n",
    "    markerstrokecolor=:green, alpha=0.5, series_annotations = text.(zero_up, :bottom, :red, :size, 10), \n",
    "    annotationhalign = :hcenter, label=\"Zero up-cross points\")\n",
    "\n",
    "# heave Threshold set at 10mm. Refer to Section 9 Wave statistics pp. 9-10 in Datawell Library Manual\n",
    "threshold = 0.05\n",
    "\n",
    "wse_1 = hline!([threshold; threshold], lw=0.2, ls =:dot, c=:red, label=\"Threshold (\"*L\"\\pm\"*string(threshold)*\")\\n\")\n",
    "wse_1 = hline!([-threshold; -threshold], lw=0.2, ls =:dot, c=:red, label=\"\")\n",
    "\n",
    "##wse_1 = hline!([stdev_3; stdev_3], lw=0.2, ls =:dot, c=:green, label=\"3 sigma\")\n",
    "##wse_1 = hline!([-stdev_3; -stdev_3], lw=0.2, ls =:dot,  c=:green, label=\"\")\n",
    "\n",
    "##wse_plot = plot(wse_point,wse_1, size = (1400, 600),xlim=(length(heave)-100,length(heave)), ylim=(-1.5,1.5), framestyle = :box, \n",
    "wse_plot = plot(wse_1, size = (1400, 600),xlim=(0,100), xlabel=\"Time (s)\", ylabel=\"Displacement (m)\", ylim=(-1.5,1.5), framestyle = :box,     \n",
    "    fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    margin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "#save plot\n",
    "savefig(\".\\\\plot.png\")\n",
    "\n",
    "display(wse_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12fe20",
   "metadata": {},
   "source": [
    "## Identify individual waves and calculate time-domain heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_zero_up = []; crest_points = []; trough_points = []\n",
    "i = 1; j = 2\n",
    "\n",
    "while j < length(zero_up)-1\n",
    "    \n",
    "    crest = maximum(heave[zero_up[i]:zero_up[j]])\n",
    "    crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "    trough = minimum(heave[crest_point:zero_up[j]])\n",
    "\n",
    "    # Check that crest higher than threshold AND trough less than threshold - Possible Valid Wave!!\n",
    "    if (crest > threshold) & (trough < -threshold)\n",
    "        crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "        trough_point = crest_point + argmin(heave[crest_point:zero_up[j]]) - 1\n",
    "        \n",
    "        push!(crest_points,crest_point)\n",
    "        push!(trough_points,trough_point)\n",
    "        \n",
    "        next_crest = maximum(heave[zero_up[j]:zero_up[j+1]])\n",
    "        \n",
    "        # Check that NEXT crest also exceeds threshold (if so then Valid Wave)\n",
    "        if (next_crest > threshold)\n",
    "##            println(\"Crest found at \",crest_point,\" Trough at \",trough_point)\n",
    "            push!(valid_zero_up,(zero_up[i],zero_up[j]));\n",
    "            i = j\n",
    "        end\n",
    "        \n",
    "    end\n",
    "\n",
    "    j = j+1\n",
    "    \n",
    "end\n",
    "\n",
    "# Process last recorded wave\n",
    "#i = j\n",
    "#j = j+1\n",
    "\n",
    "crest = maximum(heave[zero_up[i]:zero_up[j]])\n",
    "trough = minimum(heave[zero_up[i]:zero_up[j]])\n",
    "\n",
    "if (crest > threshold) & (trough < -threshold)\n",
    "\n",
    "    crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "    trough_point = crest_point + argmin(heave[crest_point:zero_up[j]]) - 1\n",
    "    push!(valid_zero_up,(zero_up[i],zero_up[j]));\n",
    "\n",
    "end\n",
    "\n",
    "heights = []\n",
    "\n",
    "for i in 1:length(valid_zero_up)\n",
    "    \n",
    "    crest = maximum(heave[valid_zero_up[i][1]:valid_zero_up[i][2]]);\n",
    "    trough = minimum(heave[valid_zero_up[i][1]:valid_zero_up[i][2]]);\n",
    "    push!(heights,crest - trough)\n",
    "##    @printf(\"Wave %d = %2.3f\\n\",i,crest - trough)\n",
    "\n",
    "end \n",
    "\n",
    "# Get time-domain height parameters\n",
    "sorted_heights = sort(heights, rev=true) # sort heights in reverse order heighestwave to loheave wave\n",
    "hmax = maximum(sorted_heights)\n",
    "hs = mean(sorted_heights[1:Int(ceil(length(sorted_heights)/3))])\n",
    "h10 = mean(sorted_heights[1:Int(ceil(length(sorted_heights) / 10))])\n",
    "hmean = mean(sorted_heights)\n",
    "\n",
    "@printf(\"%s; Waves = %3d; Hmean = %4.2fm; Hs = %4.2fm; H10 = %4.2fm; Hmax = %4.2fm\\n\",Dates.format(start_date, \"yyyy-mm-dd HH:MM\"),length(heights), hmean, hs, h10, hmax)\n",
    "\n",
    "## Locate the zero-crossing points\n",
    "\n",
    "x_point = []\n",
    "for i in 1:length(valid_zero_up)\n",
    "    push!(x_point,valid_zero_up[i][1] + abs(heave[valid_zero_up[i][1]]) / (heave[valid_zero_up[i][1]+1] - heave[valid_zero_up[i][1]]))\n",
    "end\n",
    "\n",
    "# Process final zero-crossing point\n",
    "i = length(valid_zero_up)\n",
    "push!(x_point,valid_zero_up[i][2] + abs(heave[valid_zero_up[i][2]]) / (heave[valid_zero_up[i][2]+1] - heave[valid_zero_up[i][2]]))\n",
    "\n",
    "ix = 15\n",
    "\n",
    "# Do plots\n",
    "wse_1 = plot(wse_point./2.56, heave[wse_point], lw=2, c=:blue, alpha=0.5, label = \"WSE's\", fillrange = 0, fillalpha = 0.0075, fillcolor = :blue)\n",
    "wse_1 = scatter!(wse_point./2.56, heave[wse_point], c=:white, ms=3, \n",
    "    markerstrokecolor=:blue, alpha=0.5, markerstrokewidth=0.5,label=\"WSE points\")\n",
    "wse_1 = scatter!(zero_up[1:ix]./2.56, heave[zero_up[1:ix]], ms=3, c=:lightgreen, \n",
    "    markerstrokecolor=:lightgreen, series_annotations = text.(zero_up, :bottom, :red, :size, 10), \n",
    "    annotationhalign = :hcenter, label=\"Zero up-cross points\\n\")\n",
    "\n",
    "# heave Threshold set at 10mm. Refer to Section 9 Wave statistics pp. 9-10 in Datawell Library Manual\n",
    "threshold = 0.05 \n",
    "\n",
    "wse_1 = hline!([threshold; threshold], lw=0.2, ls =:dot, c=:red, label=\"Threshold\\n\")\n",
    "wse_1 = hline!([-threshold; -threshold], lw=0.2, ls =:dot, c=:red, label=\"\")\n",
    "\n",
    "wse_1 = scatter!(x_point./2.56, zeros(length(x_point)), c=:yellow, ms=5, \n",
    "    markerstrokecolor=:yellow, markershape=:diamond, label=\"Zero-crossing points\")\n",
    "\n",
    "\n",
    "#wse_plot = plot(wse_1, size = (1400, 800),xlim=(length(heave)-100,length(heave)), ylim=(-1.5,1.5), framestyle = :box, \n",
    "wse_plot = plot(wse_1, size = (1400, 600), xlabel=\"Time (s)\", ylabel=\"Displacement (m)\", xlim=(20,60), ylim=(-1.5,1.5), framestyle = :box,     \n",
    "    fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    margin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "#save plot\n",
    "savefig(\".\\\\plot.png\")\n",
    "\n",
    "display(wse_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3565fdad",
   "metadata": {},
   "source": [
    "## Calculate time-domain periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_df = DataFrame(Date = [], Hmax = [], Thmax = [], Tmax = [], Htmax = [], Havg = [], \n",
    "    Tavg = [], Hsrms = [], Nw = [], Nc = [], Epsilon = [], Coverage = [])\n",
    "sample_frequency = 2.56 # Hertz Mk4\n",
    "periods = []\n",
    "\n",
    "for i in 1:length(x_point)-1\n",
    "    push!(periods,(x_point[i+1]-x_point[i]) / sample_frequency) # wave period in seconds\n",
    "end\n",
    "\n",
    "sorted_periods = sort(periods, rev=true) # sort periods in reverse order longest period to shortest period\n",
    "tmean = mean(sorted_periods)\n",
    "ths = periods[argmin(abs.(heights .- hs))] \n",
    "th10 = periods[argmin(abs.(heights .- h10))]\n",
    "thmax = periods[argmax(heights)]\n",
    "tmax = maximum(sorted_periods)\n",
    "\n",
    "# get Datawell parameters from f29_df\n",
    "row = f29_df[f29_df.Date .== start_date + Minute(30), :]\n",
    "\n",
    "# Print results\n",
    "@printf(\"\\nQGHL values:     \")\n",
    "@printf(\"%s; Waves = %3d; Hmean = %5.2fm; Hs = %5.2fm; H10 = %5.2fm; Hmax = %5.2fm;\",Dates.format(start_date, \"yyyy-mm-dd HH:MM\"),length(heights), hmean, hs, h10, hmax)\n",
    "@printf(\" Tmean = %5.2fs; THs = %5.2fs; TH10 = %5.2fs; THmax = %5.2fs; Tmax = %5.2fs\",tmean,ths,th10,thmax,tmax)\n",
    "\n",
    "@printf(\"\\nDatawell values: \")\n",
    "@printf(\"%s; Waves = %3d; Hmean = %5.2fm; Hs = %5.2fm; H10 = %5.2fm; Hmax = %5.2fm;\",Dates.format(row.Date[1], \"yyyy-mm-dd HH:MM\"),row.Nw[1], row.Havg[1], row.H3[1], row.H10[1], row.Hmax[1])\n",
    "@printf(\" Tmean = %5.2fs; THs = %5.2fs; TH10 = %5.2fs; THmax = %5.2fs\\n\",row.Tavg[1],row.TH3[1],row.TH10[1],row.THmax[1])\n",
    "\n",
    "\n",
    "## Plot wave heights and periods\n",
    "\n",
    "title_string = Dates.format(start_date, \"dd/mm/yyyy HH:MM\")\n",
    "\n",
    "wave_heights = hline([hmax; hmax], lw=1, c=:red, label=\"\")\n",
    "wave_heights = hline!([h10; h10], lw=1.5, c=:pink, label=\"\")\n",
    "wave_heights = hline!([hs; hs], lw=1, c=:blue, label=\"\")\n",
    "wave_heights = hline!([hmean; hmean], lw=1.5, c=:green, label=\"\")\n",
    "\n",
    "wave_heights = annotate!([15], [hmax*1.05], text(\"Hmax \" * string(round(hmax, digits=2)) * \"m\", :red, 10), :top)\n",
    "wave_heights = annotate!([15], [h10*1.05], text(\"H10 \" * string(round(h10, digits=2)) * \"m\", :pink, 10), :top)\n",
    "wave_heights = annotate!([15], [hs*1.05], text(\"Hs \" * string(round(hs, digits=2)) * \"m\", :blue, 10), :top)\n",
    "wave_heights = annotate!([15], [hmean*1.05], text(\"Hmean \" * string(round(hmean, digits=2)) * \"m\", :green, 10), :top)\n",
    "\n",
    "\n",
    "wave_heights = plot!(heights, lw=2, c=:\"#4a536b\", fillrange = 0, fillalpha = 0.035, fillcolor = :\"#4a536b\",\n",
    "    ylim=(0,hmax*1.1), title=title_string, ylabel=\"Wave height (m)\", label=\"\")\n",
    "\n",
    "min_h3_wave = minimum(sorted_heights[1:Int(ceil(length(sorted_heights)/3))])\n",
    "# show which waves were used in calculation of Hs\n",
    "wave_heights = scatter!(findall(i->(i>=min_h3_wave), heights),heights[findall(i->(i>=min_h3_wave), heights)], ms=4, mc=:lightblue, ma=0.25, label=\"\")\n",
    "\n",
    "wave_periods = hline([tmax; tmax], lw=1, c=:red, label=\"\")\n",
    "wave_periods = hline!([thmax; thmax], lw=1.5, c=:pink, label=\"\")\n",
    "wave_periods = hline!([ths; ths], lw=1, c=:blue, label=\"\")\n",
    "\n",
    "wave_periods = annotate!([15], [tmax*1.05], text(\"Tmax \" * string(round(tmax, digits=2)) * \"s\", :red, 10), :top)\n",
    "wave_periods = annotate!([15], [thmax*1.05], text(\"THmax \" * string(round(thmax, digits=2)) * \"s\", :pink, 10), :top)\n",
    "wave_periods = annotate!([15], [ths*1.05], text(\"THs \" * string(round(ths, digits=2)) * \"s\", :blue, 10), :top)\n",
    "\n",
    "wave_periods = plot!(periods, lw=2, c=:red, fillrange = 0, fillalpha = 0.025, fillcolor = :red, label=\"\",\n",
    "    ylim=(0,tmax*1.1), xlabel=\"Wave number\", ylabel=\"Wave period (s)\")\n",
    "\n",
    "wave_heights_plot = plot(wave_heights, wave_periods, layout = (2, 1), size = (1400, 800), xlim=(0,length(heights)*1.015),\n",
    "    framestyle = :box, titlefontsize=12, fg_legend=:transparent, bg_legend=:transparent,\n",
    "    leftmargin = 15Plots.mm, bottommargin = 15Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "display(wave_heights_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e32cdb",
   "metadata": {},
   "source": [
    "## Plot normal distribution on WSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "global title_string = \"JJ\"\n",
    "plot_normal(heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2041d",
   "metadata": {},
   "source": [
    "## Do Rayleigh plot of wave heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rayleigh(heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289b989",
   "metadata": {},
   "source": [
    "## Calculate declination and Inclination for record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "##############################################################################################\n",
    "## Using model located at http://www.geomag.bgs.ac.uk/data_service/models_compass/wmm_calc.html\n",
    "## But different values from https://www.ngdc.noaa.gov/geomag/calculators/magcalc.shtml#igrfgrid\n",
    "##############################################################################################\n",
    "##############################################################################################\n",
    "\n",
    "using XLSX\n",
    "using CategoricalArrays\n",
    "\n",
    "function get_lower_and_upper(year_dec_df, year_inc_df, lower_lat, lower_lon, upper_lat, upper_lon)\n",
    "################################################    \n",
    "\n",
    "    # get the declinations for lower latitude\n",
    "    lower_lat_lower_lon_declination = year_dec_df[findfirst(year_dec_df.Lat .== lower_lat),string(lower_lon)]\n",
    "##    println(\"Lower Lat & Lower Lon \", lower_lat,' ',lower_lon,' ' ,lower_lat_lower_lon_declination)\n",
    "    lower_lat_upper_lon_declination = year_dec_df[findfirst(year_dec_df.Lat .== lower_lat),string(upper_lon)]\n",
    "##    println(\"Lower Lat & Upper Lon \", lower_lat,' ',upper_lon,' ' ,lower_lat_upper_lon_declination)\n",
    "\n",
    "    # get the declinations for upper latitude\n",
    "    upper_lat_lower_lon_declination = year_dec_df[findfirst(year_dec_df.Lat .== upper_lat),string(lower_lon)]\n",
    "##    println(\"Upper Lat & Lower Lon \", upper_lat,' ',lower_lon,' ' ,upper_lat_lower_lon_declination)\n",
    "    upper_lat_upper_lon_declination = year_dec_df[findfirst(year_dec_df.Lat .== upper_lat),string(upper_lon)]\n",
    "##    println(\"Upper Lat & Upper Lon \", upper_lat,' ',upper_lon,' ' ,upper_lat_upper_lon_declination)\n",
    "\n",
    "    # get the inclinations for lower latitude\n",
    "    lower_lat_lower_lon_inclination = year_inc_df[findfirst(year_inc_df.Lat .== lower_lat),string(lower_lon)]\n",
    "##    println(\"Lower Lat & Lower Lon \", lower_lat,' ',lower_lon,' ' ,lower_lat_lower_lon_inclination)\n",
    "    lower_lat_upper_lon_inclination = year_inc_df[findfirst(year_inc_df.Lat .== lower_lat),string(upper_lon)]\n",
    "##    println(\"Lower Lat & Upper Lon \", lower_lat,' ',upper_lon,' ' ,lower_lat_upper_lon_inclination)\n",
    "\n",
    "    # get the inclinations for upper latitude\n",
    "    upper_lat_lower_lon_inclination = year_inc_df[findfirst(year_inc_df.Lat .== upper_lat),string(lower_lon)]\n",
    "##    println(\"Upper Lat & Lower Lon \", upper_lat,' ',lower_lon,' ' ,upper_lat_lower_lon_inclination)\n",
    "    upper_lat_upper_lon_inclination = year_inc_df[findfirst(year_inc_df.Lat .== upper_lat),string(upper_lon)]\n",
    "##    println(\"Upper Lat & Upper Lon \", upper_lat,' ',upper_lon,' ' ,upper_lat_upper_lon_inclination)\n",
    "    \n",
    "    return(lower_lat_lower_lon_declination, lower_lat_upper_lon_declination, upper_lat_upper_lon_declination, upper_lat_lower_lon_declination, \n",
    "                lower_lat_lower_lon_inclination, lower_lat_upper_lon_inclination, upper_lat_upper_lon_inclination, upper_lat_lower_lon_inclination)\n",
    "    \n",
    "end    # get_lower_and_upper()\n",
    "    \n",
    "\n",
    "function get_point_value(lat_diff, lon_diff, upper_lower, lower_lower, upper_upper, lower_upper)\n",
    "################################################    \n",
    "# function to calculate declination or inclination of point located with grid cell\n",
    "    \n",
    "    # first using latitude differences\n",
    "    lower_diff = upper_lower - lower_lower\n",
    "    upper_diff = upper_upper - lower_upper\n",
    "\n",
    "##    println(lower_diff,' ',upper_diff)\n",
    "\n",
    "    lower_record = lower_lower - lower_diff*lat_diff\n",
    "    upper_record = lower_upper - upper_diff*lat_diff\n",
    "\n",
    "    lon_record_using_latitude = lower_record + (upper_record-lower_record)*lon_diff\n",
    "\n",
    "##    println(lower_record,' ',upper_record,' ',lon_record_using_latitude)\n",
    "    \n",
    "    # second using longitude differences\n",
    "    lower_diff = lower_upper - lower_lower\n",
    "    upper_diff = upper_upper - upper_lower\n",
    "\n",
    "##    println(lower_diff,' ',upper_diff)\n",
    "\n",
    "    lower_record = lower_lower + lower_diff*lon_diff\n",
    "    upper_record = upper_lower + upper_diff*lon_diff\n",
    "\n",
    "    lon_record_using_longitude = lower_record - (upper_record-lower_record)*lat_diff\n",
    "\n",
    "##    println(lower_record,' ',upper_record,' ',lon_record_using_longitude)\n",
    "    \n",
    "    # return mean value of the latitude and longitude calculations\n",
    "    return(mean([lon_record_using_longitude,lon_record_using_latitude]))\n",
    "    \n",
    "end    # get_point_value()\n",
    "\n",
    "\n",
    "# Get approximate date of record\n",
    "start_year = Dates.year(f80_df.Date[1])\n",
    "end_year = start_year + 1\n",
    "record_month = Dates.month(f80_df.Date[1])\n",
    "\n",
    "@printf(\"Calculation date = 01/%2.2d/%4.4d using World Magnetic Model\\n\", record_month, start_year)\n",
    "# Determine first worksheet number\n",
    "start_sheet = indexin(start_year,[2023, 2024, 2025])[1] + 1\n",
    "end_sheet = start_sheet + 1\n",
    "\n",
    "# Read Declination and Inclination values from file\n",
    "excel_directory = \".\\\\\" \n",
    "excel_file = excel_directory*\"Declination_and_Inclination_2023_2024.xlsx\"\n",
    "buoys_df = DataFrame(XLSX.readtable(excel_file,1,))\n",
    "start_dec_df = DataFrame(XLSX.readtable(excel_file,start_sheet,))\n",
    "end_dec_df = DataFrame(XLSX.readtable(excel_file,end_sheet,))\n",
    "                \n",
    "start_inc_df = DataFrame(XLSX.readtable(excel_file,start_sheet+3,))\n",
    "end_inc_df = DataFrame(XLSX.readtable(excel_file,end_sheet+3,));\n",
    "\n",
    "# Get a representative Lat and Lon for the record\n",
    "record_lat = (mode(f80_df.Latitude))\n",
    "record_lon = mode(f80_df.Longitude);\n",
    "@printf(\"Buoy position from GPS: %4.5f° %4.5f°\\n\", record_lat, record_lon)\n",
    "\n",
    "#get integer latitudes above and below record latitude\n",
    "lower_lat = trunc(Int, record_lat)\n",
    "upper_lat = lower_lat - 1\n",
    "\n",
    "#get integer longitudes above and below record longitude\n",
    "lower_lon = trunc(Int, record_lon)\n",
    "upper_lon = lower_lon + 1\n",
    "\n",
    "\n",
    "start_lower_lat_lower_lon_declination, start_lower_lat_upper_lon_declination, start_upper_lat_upper_lon_declination, start_upper_lat_lower_lon_declination, \n",
    "    start_lower_lat_lower_lon_inclination, start_lower_lat_upper_lon_inclination, start_upper_lat_upper_lon_inclination, start_upper_lat_lower_lon_inclination =\n",
    "        get_lower_and_upper(start_dec_df, start_inc_df, lower_lat, lower_lon, upper_lat, upper_lon)\n",
    "\n",
    "end_lower_lat_lower_lon_declination, end_lower_lat_upper_lon_declination, end_upper_lat_upper_lon_declination, end_upper_lat_lower_lon_declination, \n",
    "    end_lower_lat_lower_lon_inclination, end_lower_lat_upper_lon_inclination, end_upper_lat_upper_lon_inclination, end_upper_lat_lower_lon_inclination =\n",
    "        get_lower_and_upper(end_dec_df, end_inc_df, lower_lat, lower_lon, upper_lat, upper_lon)\n",
    "\n",
    "lat_diff = record_lat - lower_lat\n",
    "lon_diff = record_lon - lower_lon\n",
    "\n",
    "# calculate declination and inclination of records position at start of year\n",
    "start_declination = get_point_value(lat_diff, lon_diff, start_upper_lat_lower_lon_declination, start_lower_lat_lower_lon_declination, start_upper_lat_upper_lon_declination, start_lower_lat_upper_lon_declination)\n",
    "start_inclination = get_point_value(lat_diff, lon_diff, start_upper_lat_lower_lon_inclination, start_lower_lat_lower_lon_inclination, start_upper_lat_upper_lon_inclination, start_lower_lat_upper_lon_inclination)\n",
    "\n",
    "# calculate declination and inclination of records position at end of year\n",
    "end_declination = get_point_value(lat_diff, lon_diff, end_upper_lat_lower_lon_declination, end_lower_lat_lower_lon_declination, end_upper_lat_upper_lon_declination, end_lower_lat_upper_lon_declination)\n",
    "end_inclination = get_point_value(lat_diff, lon_diff, end_upper_lat_lower_lon_inclination, end_lower_lat_lower_lon_inclination, end_upper_lat_upper_lon_inclination, end_lower_lat_upper_lon_inclination)\n",
    "\n",
    "@printf(\"01/01/%4d Declination = %4.5f; Inclination = %4.5f\\n\", start_year, start_declination, start_inclination)\n",
    "@printf(\"01/01/%4d Declination = %4.5f; Inclination = %4.5f\\n\", end_year, end_declination, end_inclination)\n",
    "\n",
    "# get the declination and inclination using start date + month / 12\n",
    "declination = start_declination + (end_declination-start_declination)*record_month/12\n",
    "inclination = start_inclination + (end_inclination-start_inclination)*record_month/12\n",
    "@printf(\"01/%2.2d/%4d Declination = %4.5f; Inclination = %4.5f\\n\", record_month, start_year, declination, inclination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the estimated values of magnetic declination and inclination based on the current World Magnetic Model (WMM) or the International Geomagnetic Reference Field (IGRF) model.\n",
    "using XLSX\n",
    "using CategoricalArrays\n",
    "\n",
    "# Read Declination and Inclination values from file\n",
    "excel_directory = \".\\\\\" \n",
    "\n",
    "# Select \n",
    "##excel_file = excel_directory*\"IGRF_13_Declination_and_Inclination.xlsx\"\n",
    "excel_file = excel_directory*\"WMM_2020_2024_Declination_and_Inclination.xlsx\"\n",
    "\n",
    "dec_df = DataFrame(XLSX.readtable(excel_file,1,))\n",
    "inc_df = DataFrame(XLSX.readtable(excel_file,2,));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80991d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the declination and inclination of the four points bounding the record position\n",
    "dec_box = dec_df[(dec_df.Year .== start_year) .&& (upper_lat .<= dec_df.Latitude .<= lower_lat) .&& (lower_lon .<= dec_df.Longitude .<= upper_lon),:]\n",
    "inc_box = inc_df[(inc_df.Year .== start_year) .&& (upper_lat .<= inc_df.Latitude .<= lower_lat) .&& (lower_lon .<= inc_df.Longitude .<= upper_lon),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac707b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the declination and inclination of the four points bounding the record position\n",
    "dec_box = dec_df[(dec_df.Year .== start_year) .&& (upper_lat .<= dec_df.Latitude .<= lower_lat) .&& (lower_lon .<= dec_df.Longitude .<= upper_lon),:]\n",
    "inc_box = inc_df[(inc_df.Year .== start_year) .&& (upper_lat .<= inc_df.Latitude .<= lower_lat) .&& (lower_lon .<= inc_df.Longitude .<= upper_lon),:]\n",
    "\n",
    "dec_vals = dec_box.Declination\n",
    "inc_vals = inc_box.Inclination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c85642",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_box = dec_df[(dec_df.Year .== start_year) .&& (upper_lat .<= dec_df.Latitude .<= lower_lat) .&& (lower_lon .<= dec_df.Longitude .<= upper_lon),:]\n",
    "inc_box = inc_df[(inc_df.Year .== start_year) .&& (upper_lat .<= inc_df.Latitude .<= lower_lat) .&& (lower_lon .<= inc_df.Longitude .<= upper_lon),:]\n",
    "dec_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e99fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_point_value(lat_diff, lon_diff, start_upper_lat_lower_lon_declination, start_lower_lat_lower_lon_declination, start_upper_lat_upper_lon_declination, start_lower_lat_upper_lon_declination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57aad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = dec_box.Declination\n",
    "bb = inc_box.Inclination\n",
    "\n",
    "get_point_value(lat_diff, lon_diff, aa[2], aa[1], aa[4], aa[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf811d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat(infil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "3428383 /48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b27d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "readdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "infil = \"C:\\\\QGHL\\\\Wave_data\\\\Bilinga\\\\Bilinga_4224}2021-09-04T00h00Z.hva\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d08984",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitpath(splitext(infil)[1])[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitext(splitpath(infil)[end])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open(infil) do f\n",
    "  seekend(f)\n",
    "  skip(f, -1)\n",
    "  aa = read(f, String);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb027b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f23_df[13:33,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307de7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements[findall(>=(2048), displacements)] = displacements[findall(>=(2048), displacements)] .- 4096;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7107ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0.457*sinh.(displacements/457), size=(1800,500), xlim=(50000,75000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8ae12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements = []\n",
    "    \n",
    "for i in arry\n",
    "    append!(displacements,parse(Int, SubString.(i, 1, 1), base=16)*16^2 + parse(Int, SubString.(i, 2, 2), base=16)*16^1 + parse(Int, SubString.(i, 3, 3), base=16)*16^0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(heave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "4608*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1ded3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
