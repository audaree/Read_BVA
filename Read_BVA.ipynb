{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c827e9",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f61a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Julia program to read a selected .BVA file and display 30-minute time series plots\n",
    "## JW October 2022\n",
    "#using ContinuousWavelets \n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using Gtk\n",
    "using LaTeXStrings\n",
    "using NativeFileDialog\n",
    "using Plots, Printfget_matches\n",
    "using Statistics #, StatsPlots\n",
    "#using Suppressor: @suppress\n",
    "#using Wavelets\n",
    "\n",
    "##import Pkg; Pkg.add(\"Suppressor\")\n",
    "## See https://github.com/JuliaIO/Suppressor.jl\n",
    "##using Suppressor: @suppress\n",
    "\n",
    "include(\"./read_BVA_processing_tools.jl\")\n",
    "include(\"./read_BVA_plotting_tools.jl\")\n",
    "\n",
    "function get_matches(Data, f23_df)\n",
    "##################################\n",
    "    \n",
    "    # Create a dictionary to store indices of hex strings in Data\n",
    "    index_dict = Dict{String, Vector{Int}}()\n",
    "    \n",
    "    # Populate the dictionary\n",
    "    for (i, hex_str) in enumerate(Data)\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(index_dict[hex_str], i)\n",
    "        else\n",
    "            index_dict[hex_str] = [i]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Initialize a vector to store indices\n",
    "    matching_indices = []\n",
    "    \n",
    "    # Iterate through each hex string in f23_df and lookup in the dictionary\n",
    "    for hex_str in f23_df.Match_vector\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(matching_indices, index_dict[hex_str][1])\n",
    "        else\n",
    "            push!(matching_indices, nothing)  # If no match found, store an empty vector\n",
    "        end\n",
    "    end\n",
    "\n",
    "    f23_df[!,\"Data_vector\"] = matching_indices\n",
    "\n",
    "    return(f23_df)\n",
    "\n",
    "end    # get_matches()\n",
    "\n",
    "\n",
    "# Need to check first row of the f23_df in case 23:00 is stored there\n",
    "function f23_first_row_check(f23_df)\n",
    "################################\n",
    "    \n",
    "    # Get the first row of the DataFrame\n",
    "    first_row = first(f23_df)\n",
    "    \n",
    "    # Check if the time of the first row's Date column is 23:00:00\n",
    "    time_of_first_row = Time(first_row.Date)\n",
    "\n",
    "    if time_of_first_row == Time(23, 0, 0)\n",
    "\n",
    "        if ismissing(first_row.Data_vector) || isnothing(first_row.Data_vector) || isnan(first_row.Data_vector)\n",
    "            f23_df = f23_df[2:end, :]  # Drop the first row\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "    return(f23_df)\n",
    "    \n",
    "    end    # f23_first_row_check()\n",
    "\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           START OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "# Select a HVA daily .CSV file\n",
    "infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Bris\\\\BVA\\\\\", filterlist=\"*BVA\");\n",
    "println(\"Selected \",infil)\n",
    "#Change the type-interpretation of the binary file data to unsigned integer\n",
    "println(\"Reading BINARY data from \",infil)\n",
    "data = reinterpret(UInt8, read(infil));\n",
    "\n",
    "# turn the data vector into a matrix of 12 values matching hexadecimal bytes - see DWTP 2.1 p.18\n",
    "cols = 12\n",
    "rows = Int(length(data) / cols)\n",
    "mat = reshape(view(data, :), cols, :);\n",
    "\n",
    "# Interleave last 4 matrix columns to form packet vector\n",
    "## based on mschauer @ https://discourse.julialang.org/t/combining-two-arrays-with-alternating-elements/15498/2\n",
    "packet = collect(Iterators.flatten(zip(mat[10,:],mat[11,:],mat[12,:])));\n",
    "\n",
    "# find all occurrences of 0x7e in packet vector\n",
    "aa = findall(x->x.==0x7e, vec(packet));\n",
    "\n",
    "# Create the df's to hold the processed data and setup their column structure\n",
    "f20_vals = []; f21_vals = []; f23_vals = []; f25_vals = []; f26_vals = []; f28_vals = []; f29_vals = [];\n",
    "    f80_vals = []; f81_vals = []; f82_vals = []; fc1_vals = []; fc3_vals = []\n",
    "\n",
    "f20_df = DataFrame(Date = [], Segments = [], Smax = [])\n",
    "for i in 0:99\n",
    "    col_name = \"S$i\"\n",
    "    f20_df[!,col_name] = []\n",
    "end\n",
    "f21_df = DataFrame(Date = [], Segments = [])\n",
    "\n",
    "for i in 0:99\n",
    "    col_name = \"Dir$i\"\n",
    "    f21_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"Spread$i\"\n",
    "    f21_df[!,col_name] = []\n",
    "end\n",
    "f23_df = DataFrame(Date = [], Segments = [], Match_vector = [], Sample_number = [])\n",
    "f25_df = DataFrame(Date = [], Segments = [], Hs = [], Ti = [], Te = [], T1 = [], Tz = [], T3 = [], Tc = [], \n",
    "    Rp = [], Tp = [], Smax = [], Theta_p = [], Sigma_p = [])\n",
    "f26_df = DataFrame(Date = [], Hmax = [], Thmax = [], Tmax = [], Htmax = [], Havg = [], Tavg = [], Hsrms = [], \n",
    "    Nw = [], Nc = [], Epsilon = [], Coverage = [])\n",
    "f28_df = DataFrame(Date = [], Segments = [])\n",
    "for i in 0:99\n",
    "    col_name = \"m2_$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"n2_$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "for i in 0:99\n",
    "    col_name = \"k$i\"\n",
    "    f28_df[!,col_name] = []\n",
    "end\n",
    "f29_df = DataFrame(Date = [], Coverage = [], Nw = [], Epsilon = [], Hmax = [], THmax = [], H10 = [], TH10 = [], H3 = [], \n",
    "    TH3 = [], Havg = [], Tavg = [])\n",
    "for i in 0:22\n",
    "    col_name = \"Hq$i\"\n",
    "    f29_df[!,col_name] = []\n",
    "end\n",
    "f80_df = DataFrame(Date = [], Latitude = [], Longitude = [])\n",
    "f81_df = DataFrame(Date = [], SST = [])\n",
    "f82_df = DataFrame(Date = [], Firmware = [], Speed = [], Direction = [], SST = [])\n",
    "fc1_df = DataFrame(Date = [], Firmware = [], Hatch_uid = [], Hull_uid = [], Uptime = [], Battery_energy = [], Boostcaps_energy = [],\n",
    "    Hatch_temp = [], Battery_voltage = [], Batteries_per_section = [], Battery_section_number = [], Initial_battery_energy = [], Ov = [], Cv = [],\n",
    "    Ox = [], Oy = [], Cx = [], Cy = [], Mu0 = [], Sigma0 = [], Mui = [], Sigmai = [], Muh = [], Sigmah = [], Cpitch = [], Croll = [], Tensor = [])\n",
    "fc3_df = DataFrame(Date = [], Battery_life = [])\n",
    "\n",
    "# determine number of records\n",
    "max_val = length(aa)-1\n",
    "\n",
    "# Decode the packet data to messages\n",
    "# refer to Section 2.1.2 Decoding the packet data to messages p. 20\n",
    "messages = []\n",
    "\n",
    "println(\"Processing the Packet vectors - this takes time!\")\n",
    "flush(stdout)\n",
    "for i in 1:max_val\n",
    "\n",
    "    # determine packet length\n",
    "    first = aa[i]+1\n",
    "    last = aa[i+1]\n",
    "    \n",
    "    if (last-first > 1)\n",
    "        decoded = []\n",
    "        decoded = packet[first:last-1]\n",
    "        \n",
    "        bb = findall(x->x.==0x7d, vec(decoded));\n",
    "            \n",
    "        if bb != []\n",
    "\n",
    "            # do an xor of elements with 0x7d\n",
    "            for ii in bb\n",
    "                decoded[ii+1] = decoded[ii+1] ⊻ 0x20 # set the xor value as 0x20 vide 2.1.2 p.20\n",
    "            end\n",
    "\n",
    "            # remove the 0x7d\n",
    "            deleteat!(decoded::Vector, bb)\n",
    "\n",
    "        end\n",
    "        \n",
    "        # look for vectors of the spectrum synchronisation message (0xF23)\n",
    "        if decoded[2] == 0x20\n",
    "            \n",
    "            heave_spectrum = []\n",
    "            append!(f20_vals,decoded)\n",
    "            timestamp,segments,smax,heave_spectrum = process_f20(decoded,heave_spectrum)         \n",
    "            list_1 = [timestamp,segments,smax]\n",
    "            push!(f20_df, [list_1; heave_spectrum])\n",
    "            \n",
    "        elseif decoded[2] == 0x21\n",
    "            \n",
    "            direction = []\n",
    "            spread = []\n",
    "            append!(f21_vals,decoded)\n",
    "            timestamp,segments,direction,spread = process_f21(decoded,direction,spread)\n",
    "                        \n",
    "            list1 = [timestamp,segments]\n",
    "            list2 = [direction; spread]\n",
    "            \n",
    "            push!(f21_df, [list1; list2])\n",
    "            \n",
    "        elseif decoded[2] == 0x23\n",
    "                  \n",
    "            append!(f23_vals,decoded)\n",
    "            timestamp,segments_used,match_vector,sample_number = process_f23(decoded)\n",
    "            push!(f23_df, [timestamp,segments_used,match_vector,sample_number])\n",
    "\n",
    "        elseif decoded[2] == 0x25\n",
    "\n",
    "            append!(f25_vals,decoded)\n",
    "            timestamp,segments,hs,ti,te,t1,tz,t3,tc,rp,tp,smax,theta_p,sigma_p = process_f25(decoded)\n",
    "            push!(f25_df, [timestamp,segments,hs,ti,te,t1,tz,t3,tc,rp,tp,smax,theta_p,sigma_p])\n",
    "          \n",
    "        elseif decoded[2] == 0x26\n",
    "                  \n",
    "            append!(f26_vals,decoded)\n",
    "            timestamp,hmax,thmax,tmax,htmax,havg,tavg,hsrms,nw,nc,epsilon,coverage = process_f26(decoded)\n",
    "            push!(f26_df, [timestamp,hmax,thmax,tmax,htmax,havg,tavg,hsrms,nw,nc,epsilon,coverage])\n",
    "\n",
    "        elseif decoded[2] == 0x28\n",
    "            \n",
    "            m2 = []\n",
    "            n2 = []\n",
    "            k = []\n",
    "            append!(f28_vals,decoded)\n",
    "            timestamp,segments,m2,n2,k = process_f28(decoded,m2,n2,k)\n",
    "                        \n",
    "            list1 = [timestamp,segments]\n",
    "            list2 = [m2; n2; k]\n",
    "            \n",
    "            push!(f28_df, [list1; list2])\n",
    "            \n",
    "        elseif decoded[2] == 0x29\n",
    "            hq = []\n",
    "            append!(f29_vals,decoded)\n",
    "            timestamp,coverage,nw,epsilon,hmax,thmax,h10,th10,h3,th3,havg,tavg,hq = process_f29(decoded,hq)         \n",
    "            list_1 = [timestamp,coverage,nw,epsilon,hmax,thmax,h10,th10,h3,th3,havg,tavg]\n",
    "            push!(f29_df, [list_1; hq])\n",
    "\n",
    "        elseif decoded[2] == 0x80\n",
    "            \n",
    "            append!(f80_vals,decoded)\n",
    "            timestamp,latitude,longitude = process_f80(decoded)\n",
    "            push!(f80_df, [timestamp,latitude,longitude])\n",
    "            \n",
    "        elseif decoded[2] == 0x81\n",
    "            \n",
    "            append!(f81_vals,decoded)\n",
    "            timestamp,sst = process_f81(decoded)\n",
    "            push!(f81_df, [timestamp,sst])\n",
    "            \n",
    "        elseif decoded[2] == 0x82\n",
    "            \n",
    "            append!(f82_vals,decoded)\n",
    "            timestamp,firmware,speed,direction,sst = process_f82(decoded)\n",
    "            push!(f82_df, [timestamp,firmware,speed,direction,sst])\n",
    "      \n",
    "        elseif decoded[2] == 0xc1\n",
    "            \n",
    "            append!(fc1_vals,decoded)\n",
    "            timestamp,firmware,hatch_uid,hull_uid,uptime,battery_energy,boostcaps_energy,hatch_temp,battery_voltage,\n",
    "            batteries_per_section,battery_section_number,initial_battery_energy,ov,cv,ox,oy,cx,cy,mu0,sigma0,mui,sigmai,muh,\n",
    "            sigmah,cpitch,croll,tensor = process_fc1(decoded)   \n",
    "            \n",
    "            push!(fc1_df, [timestamp,firmware,hatch_uid,hull_uid,uptime,battery_energy,boostcaps_energy,hatch_temp,\n",
    "                battery_voltage,batteries_per_section,battery_section_number,initial_battery_energy,ov,cv,ox,oy,cx,cy,mu0,\n",
    "                sigma0,mui,sigmai,muh,sigmah,cpitch,croll,tensor])\n",
    "\n",
    "        elseif decoded[2] == 0xc3\n",
    "            \n",
    "            append!(fc3_vals,decoded)\n",
    "            timestamp,ble = process_fc3(decoded)\n",
    "            push!(fc3_df, [timestamp,ble])\n",
    "\n",
    "         end\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "    \n",
    "# remove duplicates from dataframes\n",
    "f20_df = unique(f20_df)\n",
    "f21_df = unique(f21_df)\n",
    "f23_df = unique(f23_df)\n",
    "f25_df = unique(f25_df)\n",
    "f26_df = unique(f26_df)    \n",
    "f28_df = unique(f28_df)\n",
    "f29_df = unique(f29_df)\n",
    "f80_df = unique(f80_df)\n",
    "f81_df = unique(f81_df)\n",
    "f82_df = unique(f82_df)\n",
    "fc1_df = unique(fc1_df)\n",
    "fc3_df = unique(fc3_df)\n",
    "\n",
    "## Calculate the Heave, North, and West displacements\n",
    "hex_matrix = string.(mat'[:,1:9], base=16, pad=2)\n",
    "Data = [join(row) for row in eachrow(hex_matrix)];\n",
    "\n",
    "println(\"All file data read!\")\n",
    "println(\"Preparing to plot data\")\n",
    "flush(stdout)\n",
    "\n",
    "f23_df = get_matches(Data, f23_df)\n",
    "\n",
    "# remove those vectors from F23 df that are not located in the Data vector df\n",
    "f23_df = f23_first_row_check(f23_df)\n",
    "\n",
    "# Do time-series plot of available data\n",
    "plot_f29(f29_df)\n",
    "\n",
    "# Plot current speed and direction\n",
    "##plot_f82(f82_df)\n",
    "\n",
    "println(\"Select date from menu for more plots\")\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           END OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf182f-d741-4916-9cb6-53b7d5129e6e",
   "metadata": {},
   "source": [
    "### get heave data for all available dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919e1be-e785-4042-adbe-d0232c20e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_or_truncate(record, target_length=4608)\n",
    "####################################################\n",
    "\n",
    "    length(record) < target_length ? vcat(record, zeros(Float32, target_length - length(record))) :\n",
    "                                     record[1:target_length]\n",
    "\n",
    "end    # pad_or_truncate()\n",
    "\n",
    "\n",
    "function get_heave(Data, f23_df)\n",
    "################################\n",
    "    \n",
    "    heave_array = []\n",
    "    X_date = []\n",
    "    \n",
    "    for idx in 1:nrow(f23_df)\n",
    "\n",
    "        if !isnothing(f23_df.Data_vector[idx])\n",
    "    \n",
    "            start_date, start_val, end_val = get_start_end_dates(f23_df,idx)\n",
    "            if start_val > 0\n",
    "                print(\".\")\n",
    "                heave, north, west = get_hnw(Data,start_val,end_val)\n",
    "\n",
    "                # ensure we have 4608 data points\n",
    "                push!(heave_array,pad_or_truncate(heave, 4608))\n",
    "                push!(X_date,start_date)\n",
    "            end\n",
    "\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    return(hcat(heave_array...), X_date)\n",
    "\n",
    "end    # get_heave()\n",
    "\n",
    "\n",
    "X_train, X_date = get_heave(Data, f23_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672e075-fcd4-4ba6-af0c-584e069985d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Statistics, Plots, Dates, Printf\n",
    "\n",
    "plotly()\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "\n",
    "# Function to calculate confidence limits\n",
    "function calc_confidence_limits(data, confidence_interval)\n",
    "####################################################################################\n",
    "    \n",
    "    mean_val = mean(data)\n",
    "    std_dev = std(data)\n",
    "    upper_limit = mean_val + confidence_interval * std_dev\n",
    "    lower_limit = mean_val - confidence_interval * std_dev\n",
    "\n",
    "    return(lower_limit, upper_limit)\n",
    "    \n",
    "end    # calc_confidence_limits()\n",
    "\n",
    "\n",
    "function modified_z_score(data, threshold)\n",
    "##########################################\n",
    "    \n",
    "    med = median(data)\n",
    "    mad = median(abs.(data .- med))\n",
    "    mod_z_scores = 0.6745 * (data .- med) ./ mad\n",
    "\n",
    "    outlier_indices = findall(x -> abs(x) > threshold, mod_z_scores)\n",
    "    \n",
    "    return(outlier_indices, mod_z_scores)\n",
    "    \n",
    "end    # modified_z_score()\n",
    "\n",
    "# Define dynamic modified z-score threshold\n",
    "function dynamic_z_score_threshold(heave, base_threshold=3.0, k=0.5)\n",
    "####################################################################\n",
    "    \n",
    "    median_wave_height = median(heave)\n",
    "    std_wave_height = std(heave)\n",
    "    dynamic_threshold = base_threshold * (1 + k * (median_wave_height / std_wave_height))\n",
    "    \n",
    "    return(dynamic_threshold)\n",
    "    \n",
    "end    # dynamic_z_score_threshold()\n",
    "\n",
    "\n",
    "for ii in 1:10 #length(X_date)\n",
    "\n",
    "    # Initialize the plot\n",
    "    start_time = X_date[ii]\n",
    "    heave = X_train[:,ii]\n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((0:4608-1) / 2.56 * 1000000)\n",
    "    max_heave = maximum(heave)\n",
    "\n",
    "    p1 = plot(size=(1200,300), framestyle = :box, fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "        xtickfont=font(8), ytickfont=font(8),\n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridalpha=1)\n",
    "            \n",
    "    tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick,\"MM\")\n",
    "       \n",
    "#########################################################################################################################\n",
    "##    confidence_interval = 2.576  # corresponds to a 99% confidence interval (for a normal distribution)\n",
    "##    confidence_interval = 3.0  # corresponds to a 99.73% confidence interval (for a normal distribution)    \n",
    "##    confidence_interval = 3.29  # corresponds to a 99.9% confidence interval (for a normal distribution)\n",
    "\n",
    "    # Use dynamic threshold for modified z-score\n",
    "    confidence_interval = dynamic_z_score_threshold(heave)\n",
    "#########################################################################################################################    \n",
    "    \n",
    "    outlier_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "    if !isempty(outlier_indices) && any(x -> x > 0, mod_z_scores[outlier_indices])\n",
    "        scatter!(p1, xvals[outlier_indices], heave[outlier_indices], \n",
    "            markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "            markercolor=:white, markershape=:circle,\n",
    "            label=\"\") #\"Possible Outliers\")\n",
    "    end\n",
    "\n",
    "    confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "       \n",
    "    hline!(p1, [confidence_limits[1]], color=:red, lw=:0.5, linestyle=:dash, label=\"\") #\"99% Confidence Limits\")\n",
    "    hline!(p1, [confidence_limits[2]], color=:red, lw=:0.5, linestyle=:dash, label=\"\")\n",
    "    \n",
    "    plot!(p1, xvals, heave, xlims=(xvals[1],xvals[end]), lw=:0.5, lc=:blue, alpha=:0.5, \n",
    "            xticks=(tm_tick, ticks), label=Dates.format(start_time, \"yyyy-mm-dd HH:MM\"))\n",
    "\n",
    "    # Count the number of possible outliers\n",
    "    num_outliers = length(outlier_indices)\n",
    "    suspect_string = string(\"  \", num_outliers, \" Possible outliers using Confidence Interval of \", @sprintf(\"%.2f\", confidence_interval))\n",
    "    \n",
    "    # Annotate plot with the number of outliers\n",
    "    annotate!(p1, xvals[1], max_heave * 0.9, text(suspect_string, :left, 10))\n",
    "    \n",
    "    display(p1)\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d104964-b797-493b-9cc4-2ed9cfe2ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, Plots, Dates, Printf\n",
    "\n",
    "plotly()\n",
    "\n",
    "# Function to calculate confidence limits\n",
    "function calc_confidence_limits(data, confidence_interval)\n",
    "    mean_val = mean(data)\n",
    "    std_dev = std(data)\n",
    "    upper_limit = mean_val + confidence_interval * std_dev\n",
    "    lower_limit = mean_val - confidence_interval * std_dev\n",
    "    return (lower_limit, upper_limit)\n",
    "end\n",
    "\n",
    "# Function to compute modified z-scores and find outliers\n",
    "function modified_z_score(data, threshold)\n",
    "    med = median(data)\n",
    "    mad = median(abs.(data .- med))\n",
    "    mod_z_scores = 0.6745 * (data .- med) ./ mad\n",
    "    outlier_indices = findall(x -> abs(x) > threshold, mod_z_scores)\n",
    "    return outlier_indices, mod_z_scores\n",
    "end\n",
    "\n",
    "# Function for dynamic threshold based on mean wave height\n",
    "function dynamic_z_score_threshold(heave, base_threshold=3.0, k=0.5)\n",
    "    mean_wave_height = mean(heave)\n",
    "    std_wave_height = std(heave)\n",
    "    dynamic_threshold = base_threshold * (1 + k * (mean_wave_height / std_wave_height))\n",
    "    return dynamic_threshold\n",
    "end\n",
    "\n",
    "# Loop through wave records\n",
    "for ii in 1:10 #length(X_date)\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "    heave = X_train[:, ii]\n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((1:4608 .- 1) / 2.56 * 1000000)\n",
    "\n",
    "    # Plot initialization\n",
    "    p1 = plot(size=(1200, 300), framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "        legend=:topright, xtickfont=font(8), ytickfont=font(8),\n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridalpha=1)\n",
    "    \n",
    "    tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "    \n",
    "    # Calculate dynamic confidence interval\n",
    "    confidence_interval = dynamic_z_score_threshold(heave)\n",
    "\n",
    "    # Identify outliers using modified z-score\n",
    "    outlier_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "    if !isempty(outlier_indices)\n",
    "        scatter!(p1, xvals[outlier_indices], heave[outlier_indices], \n",
    "            markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "            markercolor=:white, markershape=:circle, label=\"\")\n",
    "    end\n",
    "\n",
    "    # Plot confidence limits\n",
    "    confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "    hline!(p1, [confidence_limits[1], confidence_limits[2]], color=:red, lw=0.5, linestyle=:dash, label=\"\")\n",
    "\n",
    "    # Plot heave data\n",
    "    plot!(p1, xvals, heave, xlims=(xvals[1], xvals[end]), lw=0.5, lc=:blue, alpha=0.5, \n",
    "        xticks=(tm_tick, ticks), label=Dates.format(start_time, \"yyyy-mm-dd HH:MM\"))\n",
    "\n",
    "    # Annotate plot with the number of outliers and confidence interval\n",
    "    num_outliers = length(outlier_indices)\n",
    "    suspect_string = string(\"  \", num_outliers, \" Possible outliers using Confidence Interval of \", @sprintf(\"%.2f\", confidence_interval))\n",
    "    annotate!(p1, xvals[1], maximum(heave) * 0.9, text(suspect_string, :left, 10))\n",
    "\n",
    "    display(p1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9859f2f-7e2b-4a6f-819b-ef3e2ddb7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dates.format.(X_date, \"yyyy-mm-dd HH:MM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d96c69-1289-4a88-b4d0-b50b2e51c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tk\n",
    "\n",
    "w = Toplevel(\"Select Date\", 235, 400)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, Dates.format.(X_date, \"yyyy-mm-dd HH:MM\"))\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Button(f, \"Ok\")\n",
    "pack(b)\n",
    "\n",
    "bad_array = []\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "    \n",
    "    global file_choice = get_value(lb);\n",
    "    push!(bad_array,file_choice[1])\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df36b54-44bb-4fdd-9f1d-33726ad4dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac009a7-765f-48eb-a424-e6c674a54849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f09b1-6648-4701-a4df-bbcc237a9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DateTime.(bad_array, \"yyyy-mm-dd HH:MM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b580e2-b74e-4a0c-ba6d-28403605eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert bad_array to DateTime format\n",
    "bad_dates = DateTime.(bad_array, \"yyyy-mm-dd HH:MM\")\n",
    "\n",
    "# Find indices of bad_dates in X_date\n",
    "bad_cols = findall(x -> x in bad_dates, X_date)\n",
    "\n",
    "# Remove columns from X_train whose column numbers are in bad_cols\n",
    "X_train = X_train[:, setdiff(1:size(X_train, 2), bad_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2446c4bc-ee11-4eed-ae3e-8eb8d7063880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected F:\\Card Data\\Brisbane\\Brisbane_2020-2021\\20210101.BVA\n",
      "Reading BINARY data from F:\\Card Data\\Brisbane\\Brisbane_2020-2021\\20210101.BVA\n",
      "All file data read!\n",
      "error during Tk callback: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mArgumentError: column name :Data_vector not found in the data frame\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1mlookupname\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\DataFrames\\kcA9R\\src\\other\\\u001b[39m\u001b[90m\u001b[4mindex.jl:431\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mgetindex\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\DataFrames\\kcA9R\\src\\other\\\u001b[39m\u001b[90m\u001b[4mindex.jl:440\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mgetindex\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mdf\u001b[39m::\u001b[0mDataFrame, ::\u001b[0mtypeof(!), \u001b[90mcol_ind\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[32mDataFrames\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\DataFrames\\kcA9R\\src\\dataframe\\\u001b[39m\u001b[90m\u001b[4mdataframe.jl:557\u001b[24m\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1mgetproperty\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\DataFrames\\kcA9R\\src\\abstractdataframe\\\u001b[39m\u001b[90m\u001b[4mabstractdataframe.jl:448\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mget_heave\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mData\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mf23_df\u001b[39m::\u001b[0mDataFrame\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mIn[12]:183\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1mhandle_selection\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minfil_ref\u001b[39m::\u001b[0mBase.RefValue\u001b[90m{String}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mIn[12]:216\u001b[24m\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1m(::var\"#67#68\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mevent\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mIn[12]:286\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1mjl_tcl_callback\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mfptr\u001b[39m::\u001b[0mPtr\u001b[90m{Nothing}\u001b[39m, \u001b[90minterp\u001b[39m::\u001b[0mPtr\u001b[90m{Nothing}\u001b[39m, \u001b[90margc\u001b[39m::\u001b[0mInt32, \u001b[90margv\u001b[39m::\u001b[0mPtr\u001b[90m{Ptr{UInt8}}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mTk\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\Tk\\c8ZUf\\src\\\u001b[39m\u001b[90m\u001b[4mtkwidget.jl:142\u001b[24m\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1mtcl_doevent\u001b[22m\u001b[90m (repeats 2 times)\u001b[39m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\Jim\\.julia\\packages\\Tk\\c8ZUf\\src\\\u001b[39m\u001b[90m\u001b[4mtkwidget.jl:20\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1m(::Base.var\"#726#727\"{typeof(Tk.tcl_doevent), Timer})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4masyncevent.jl:306\u001b[24m\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using DataFrames: DataFrame, ncol, nrow\n",
    "using Dates: Dates, DateTime, unix2datetime, datetime2unix, Hour, Minute, Microsecond\n",
    "using NativeFileDialog: pick_folder\n",
    "using Statistics: median, std\n",
    "using Tk: bind, Button, destroy, Frame, get_value, pack, scrollbars_add, tcl, Toplevel, Treeview\n",
    "using Plots: Plots, plot, plot!, annotate!, vline!, @layout, text, plotly\n",
    "using Printf: @sprintf\n",
    "\n",
    "plotly()\n",
    "\n",
    "rec_len = 4608\n",
    "sample_frequency = 2.56 # sample frequency in Hertz\n",
    "sample_length = 1800 # record length in seconds\n",
    "sample_rate = Float64(1/sample_frequency) # sample spacing in seconds\n",
    "\n",
    "#using Logging: NullLogger, with_logger\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "bva_directory = pick_folder()\n",
    "\n",
    "# build list of all bva files in selected directory\n",
    "#bva_files = filter(x->occursin(\".bva\",x), readdir(bva_directory));\n",
    "#bva_files = bva_files[findall(x->endswith(uppercase(x), \".bva\"), bva_files)];\n",
    "\n",
    "# Build list of all bva files (case-insensitive: handles both \".bva\" and \".BVA\")\n",
    "bva_files = filter(x -> endswith(lowercase(x), \".bva\"), readdir(bva_directory));\n",
    "\n",
    "w = Toplevel(\"Select File\", 235, 800)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, bva_files)\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1, expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Button(f, \"Exit\")\n",
    "pack(b)\n",
    "\n",
    "infil_ref = Ref(\"\")\n",
    "\n",
    "\n",
    "function get_matches(Data, f23_df)\n",
    "##################################\n",
    "    \n",
    "    # Create a dictionary to store indices of hex strings in Data\n",
    "    index_dict = Dict{String, Vector{Int}}()\n",
    "    \n",
    "    # Populate the dictionary\n",
    "    for (i, hex_str) in enumerate(Data)\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(index_dict[hex_str], i)\n",
    "        else\n",
    "            index_dict[hex_str] = [i]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Initialize a vector to store indices\n",
    "    matching_indices = []\n",
    "    \n",
    "    # Iterate through each hex string in f23_df and lookup in the dictionary\n",
    "    for hex_str in f23_df.Match_vector\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(matching_indices, index_dict[hex_str][1])\n",
    "        else\n",
    "            push!(matching_indices, nothing)  # If no match found, store an empty vector\n",
    "        end\n",
    "    end\n",
    "\n",
    "    f23_df[!,\"Data_vector\"] = matching_indices\n",
    "\n",
    "    return(f23_df)\n",
    "\n",
    "end    # get_matches()\n",
    "\n",
    "# function to calculate selected parameters from Spectrum synchronisation message (0xF23)\n",
    "function process_f23(f23_vals)\n",
    "#######################################\n",
    "    \n",
    "    # refer to DWTP (Ver. 16 January2019) Section 4.3 pp.43-44\n",
    "\n",
    "    # get Timestamp in UTC\n",
    "    timestamp = unix2datetime(parse(Int, bitstring(f23_vals[3]) * bitstring(f23_vals[4]) * bitstring(f23_vals[5]) * bitstring(f23_vals[6]); base=2))\n",
    "    \n",
    "    # convert time to Australian Eastern Standard Time\n",
    "    timestamp = timestamp + Hour(0)  # Adjust this for the correct time zone\n",
    "\n",
    "    # get Data Stamp\n",
    "    data_stamp = parse(Int, bitstring(f23_vals[7]) * bitstring(f23_vals[8]); base=2)\n",
    "\n",
    "    # get Segments Used\n",
    "    segments_used = parse(Int, bitstring(f23_vals[9]) * bitstring(f23_vals[10]) * bitstring(f23_vals[11]); base=2)\n",
    "\n",
    "    # get Sample Number\n",
    "    sample_number = parse(Int, bitstring(f23_vals[12]) * bitstring(f23_vals[13]); base=2)\n",
    "\n",
    "    # Create Match Vector\n",
    "    match_vector = lpad(string(f23_vals[14], base=16), 2, \"0\")\n",
    "    for i in 15:22\n",
    "        match_vector = match_vector * lpad(string(f23_vals[i], base=16), 2, \"0\")\n",
    "    end\n",
    "    \n",
    "    return(timestamp, segments_used, match_vector, sample_number)\n",
    "    \n",
    "end    #  process_f23()\n",
    "\n",
    "\n",
    "# convert binary data into F23_df and Hex array\n",
    "function get_hex_array(infil)\n",
    "#############################\n",
    "    \n",
    "    # Read binary data from the input file\n",
    "    println(\"Reading BINARY data from \", infil)\n",
    "    data = reinterpret(UInt8, read(infil))\n",
    "    \n",
    "    # Turn the data vector into a matrix of 12 values matching hexadecimal bytes\n",
    "    cols = 12\n",
    "    rows = Int(length(data) / cols)\n",
    "    mat = reshape(view(data, :), cols, :)\n",
    "    \n",
    "    # Calculate the Heave, North, and West displacements\n",
    "    hex_matrix = string.(mat'[:,1:9], base=16, pad=2)\n",
    "    Data = [join(row) for row in eachrow(hex_matrix)]\n",
    "    \n",
    "    println(\"All file data read!\")\n",
    "    \n",
    "    # Interleave the last 3 matrix columns (10, 11, 12) to form the packet vector\n",
    "    packet = collect(Iterators.flatten(zip(mat[10,:], mat[11,:], mat[12,:])))\n",
    "    \n",
    "    # Find all occurrences of 0x7e in the packet vector\n",
    "    aa = findall(x -> x == 0x7e, vec(packet))\n",
    "    \n",
    "    # Create DataFrame to hold the processed data\n",
    "    f23_df = DataFrame(Date = DateTime[], Segments = Int[], Match_vector = String[], Sample_number = Int[])\n",
    "    \n",
    "    # Decode the packet data into messages\n",
    "    max_val = length(aa) - 1\n",
    "    \n",
    "    for i in 1:max_val\n",
    "        first = aa[i] + 1\n",
    "        last = aa[i + 1]\n",
    "        \n",
    "        if (last - first > 1)\n",
    "            decoded = packet[first:last-1]\n",
    "            \n",
    "            # Handle the 0x7d escape sequences (XOR with 0x20)\n",
    "            bb = findall(x -> x == 0x7d, decoded)\n",
    "            for ii in bb\n",
    "                decoded[ii + 1] = decoded[ii + 1] ⊻ 0x20\n",
    "            end\n",
    "            deleteat!(decoded, bb)\n",
    "            \n",
    "            # If the message is F23 (0x23)\n",
    "            if decoded[2] == 0x23\n",
    "                timestamp, segments_used, match_vector, sample_number = process_f23(decoded)\n",
    "                push!(f23_df, [timestamp, segments_used, match_vector, sample_number])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Remove duplicates from f23_df\n",
    "    f23_df = unique(f23_df);\n",
    "\n",
    "    return(f23_df, Data)\n",
    "    \n",
    "    end    # get_hex_array()\n",
    "\n",
    "\n",
    "# Function to calculate confidence limits\n",
    "function calc_confidence_limits(data, confidence_interval)\n",
    "##########################################################\n",
    "    \n",
    "    mean_val = mean(data)\n",
    "    std_dev = std(data)\n",
    "    upper_limit = mean_val + confidence_interval * std_dev\n",
    "    lower_limit = mean_val - confidence_interval * std_dev\n",
    "    \n",
    "    return (lower_limit, upper_limit)\n",
    "    \n",
    "end    # calc_confidence_limits()\n",
    "\n",
    "\n",
    "# Function to compute modified z-scores and find outliers\n",
    "function modified_z_score(data, threshold)\n",
    "##########################################\n",
    "    \n",
    "    med = median(data)\n",
    "    mad = median(abs.(data .- med))\n",
    "    mod_z_scores = 0.6745 * (data .- med) ./ mad\n",
    "    outlier_indices = findall(x -> abs(x) > threshold, mod_z_scores)\n",
    "    \n",
    "    return(outlier_indices, mod_z_scores)\n",
    "    \n",
    "end    # modified_z_score()\n",
    "\n",
    "\n",
    "# Function for dynamic threshold based on mean wave height\n",
    "function dynamic_z_score_threshold(heave, base_threshold=3.0, k=0.5)\n",
    "    \n",
    "    mean_wave_height = mean(heave)\n",
    "    std_wave_height = std(heave)\n",
    "    dynamic_threshold = base_threshold * (1 + k * (mean_wave_height / std_wave_height))\n",
    "    \n",
    "    return(dynamic_threshold)\n",
    "    \n",
    "end    # dynamic_z_score_threshold()\n",
    "\n",
    "\n",
    "function pad_or_truncate(record, target_length=4608)\n",
    "####################################################\n",
    "\n",
    "    length(record) < target_length ? vcat(record, zeros(Float32, target_length - length(record))) :\n",
    "                                     record[1:target_length]\n",
    "\n",
    "end    # pad_or_truncate()\n",
    "\n",
    "\n",
    "function get_heave(Data, f23_df)\n",
    "################################\n",
    "    \n",
    "    heave_array = []\n",
    "    X_date = []\n",
    "    \n",
    "    for idx in 1:nrow(f23_df)\n",
    "\n",
    "        if !isnothing(f23_df.Data_vector[idx])\n",
    "    \n",
    "            start_date, start_val, end_val = get_start_end_dates(f23_df,idx)\n",
    "            if start_val > 0\n",
    "                print(\".\")\n",
    "                heave, north, west = get_hnw(Data,start_val,end_val)\n",
    "\n",
    "                # ensure we have 4608 data points\n",
    "                push!(heave_array,pad_or_truncate(heave, 4608))\n",
    "                push!(X_date,start_date)\n",
    "            end\n",
    "\n",
    "        end\n",
    "    \n",
    "    end\n",
    "\n",
    "    return(hcat(heave_array...), X_date)\n",
    "\n",
    "end    # get_heave()\n",
    "\n",
    "\n",
    "function handle_selection(infil_ref)\n",
    "####################################\n",
    "    \n",
    "    file_choice = get_value(lb)\n",
    "    infil_ref[] = bva_directory * \"\\\\\" * file_choice[1]\n",
    "    println(\"Selected \", infil_ref[])\n",
    "    flush(stdout)\n",
    "    \n",
    "    infil = infil_ref[]\n",
    "\n",
    "    f23_df, Data = get_hex_array(infil)\n",
    "\n",
    "    f23_df = get_matches(Data, f23_df)\n",
    "\n",
    "    # remove those vectors from F23 df that are not located in the Data vector df\n",
    "    f23_df = f23_first_row_check(f23_df)\n",
    "\n",
    "    X_train, X_date = get_heave(Data, f23_df);\n",
    "\n",
    "    # Loop through wave records\n",
    "    for ii in 1:10 #length(X_date)\n",
    "        \n",
    "        # Initialize variables\n",
    "        start_time = X_date[ii]\n",
    "        heave = X_train[:, ii]\n",
    "        end_time = start_time + Minute(30)\n",
    "        xvals = start_time + Microsecond.((1:4608 .- 1) / 2.56 * 1000000)\n",
    "    \n",
    "        # Plot initialization\n",
    "        p1 = plot(size=(1200, 300), framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "            legend=:topright, xtickfont=font(8), ytickfont=font(8),\n",
    "            grid=true, gridlinewidth=0.125, gridstyle=:dot, gridalpha=1)\n",
    "        \n",
    "        tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "        ticks = Dates.format.(tm_tick, \"MM\")\n",
    "        \n",
    "        # Calculate dynamic confidence interval\n",
    "        confidence_interval = dynamic_z_score_threshold(heave)\n",
    "    \n",
    "        # Identify outliers using modified z-score\n",
    "        outlier_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "        if !isempty(outlier_indices)\n",
    "            scatter!(p1, xvals[outlier_indices], heave[outlier_indices], \n",
    "                markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "                markercolor=:white, markershape=:circle, label=\"\")\n",
    "        end\n",
    "    \n",
    "        # Plot confidence limits\n",
    "        confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "        hline!(p1, [confidence_limits[1], confidence_limits[2]], color=:red, lw=0.5, linestyle=:dash, label=\"\")\n",
    "    \n",
    "        # Plot heave data\n",
    "        plot!(p1, xvals, heave, xlims=(xvals[1], xvals[end]), lw=0.5, lc=:blue, alpha=0.5, \n",
    "            xticks=(tm_tick, ticks), label=Dates.format(start_time, \"yyyy-mm-dd HH:MM\"))\n",
    "    \n",
    "        # Annotate plot with the number of outliers and confidence interval\n",
    "        num_outliers = length(outlier_indices)\n",
    "        suspect_string = string(\"  \", num_outliers, \" Possible outliers using Confidence Interval of \", @sprintf(\"%.2f\", confidence_interval))\n",
    "        annotate!(p1, xvals[1], maximum(heave) * 0.9, text(suspect_string, :left, 10))\n",
    "    \n",
    "        display(p1)\n",
    "        \n",
    "    end\n",
    "\n",
    "end    # handle_selection()\n",
    "\n",
    "\n",
    "function exit_callback()\n",
    "########################\n",
    "    \n",
    "    destroy(w)  # Close the window when Exit button is pressed\n",
    "\n",
    "end    # exit_callback()\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "    \n",
    "    exit_callback()\n",
    "    \n",
    "end    # exit bind()\n",
    "\n",
    "# Bind double-click event to the Treeview\n",
    "bind(lb, \"<Double-1>\") do event\n",
    "    \n",
    "    handle_selection(infil_ref)\n",
    "        \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3c079-5182-45ae-9272-2bfd227f00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, DataFrames, Dates\n",
    "\n",
    "# convert binary data into F23_df and Hex array\n",
    "function get_hex_array(infil)\n",
    "#############################\n",
    "    \n",
    "    # Read binary data from the input file\n",
    "    println(\"Reading BINARY data from \", infil)\n",
    "    data = reinterpret(UInt8, read(infil))\n",
    "    \n",
    "    # Turn the data vector into a matrix of 12 values matching hexadecimal bytes\n",
    "    cols = 12\n",
    "    rows = Int(length(data) / cols)\n",
    "    mat = reshape(view(data, :), cols, :)\n",
    "    \n",
    "    # Calculate the Heave, North, and West displacements\n",
    "    hex_matrix = string.(mat'[:,1:9], base=16, pad=2)\n",
    "    Data = [join(row) for row in eachrow(hex_matrix)]\n",
    "    \n",
    "    println(\"All file data read!\")\n",
    "    \n",
    "    # Interleave the last 3 matrix columns (10, 11, 12) to form the packet vector\n",
    "    packet = collect(Iterators.flatten(zip(mat[10,:], mat[11,:], mat[12,:])))\n",
    "    \n",
    "    # Find all occurrences of 0x7e in the packet vector\n",
    "    aa = findall(x -> x == 0x7e, vec(packet))\n",
    "    \n",
    "    # Create DataFrame to hold the processed data\n",
    "    f23_df = DataFrame(Date = DateTime[], Segments = Int[], Match_vector = String[], Sample_number = Int[])\n",
    "    \n",
    "    # Decode the packet data into messages\n",
    "    max_val = length(aa) - 1\n",
    "    \n",
    "    for i in 1:max_val\n",
    "        first = aa[i] + 1\n",
    "        last = aa[i + 1]\n",
    "        \n",
    "        if (last - first > 1)\n",
    "            decoded = packet[first:last-1]\n",
    "            \n",
    "            # Handle the 0x7d escape sequences (XOR with 0x20)\n",
    "            bb = findall(x -> x == 0x7d, decoded)\n",
    "            for ii in bb\n",
    "                decoded[ii + 1] = decoded[ii + 1] ⊻ 0x20\n",
    "            end\n",
    "            deleteat!(decoded, bb)\n",
    "            \n",
    "            # If the message is F23 (0x23)\n",
    "            if decoded[2] == 0x23\n",
    "                timestamp, segments_used, match_vector, sample_number = process_f23(decoded)\n",
    "                push!(f23_df, [timestamp, segments_used, match_vector, sample_number])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Remove duplicates from f23_df\n",
    "    f23_df = unique(f23_df);\n",
    "\n",
    "    return(f23_df, Data)\n",
    "    \n",
    "    end    # get_hex_array()\n",
    "\n",
    "f23_df, Data = get_hex_array(infil);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34177d1b-f29b-4c45-a798-65e626261141",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, DataFrames, DSP, NativeFileDialog, Plots, Statistics, Printf\n",
    "\n",
    "# Include necessary functions\n",
    "include(\"./read_BVA_processing_tools.jl\")\n",
    "include(\"./read_BVA_plotting_tools.jl\")\n",
    "\n",
    "# Optimized function to get matches\n",
    "function get_matches_optimized(Data, f23_df)\n",
    "    index_dict = Dict{String, Int}()\n",
    "    for (i, hex_str) in enumerate(Data)\n",
    "        index_dict[hex_str] = i\n",
    "    end\n",
    "    \n",
    "    f23_df[!,\"Data_vector\"] = [get(index_dict, hex_str, nothing) for hex_str in f23_df.Match_vector]\n",
    "    return f23_df\n",
    "end\n",
    "\n",
    "# Optimized function to check the first row of f23_df\n",
    "function f23_first_row_check_optimized(f23_df)\n",
    "    if Time(first(f23_df).Date) == Time(23, 0, 0) && \n",
    "       (ismissing(first(f23_df).Data_vector) || isnothing(first(f23_df).Data_vector))\n",
    "        f23_df = f23_df[2:end, :]\n",
    "    end\n",
    "    return f23_df\n",
    "end\n",
    "\n",
    "function process_packets(packet, aa, f20_df, f21_df, f23_df, f25_df, f26_df, f28_df, f29_df, f80_df, f81_df, f82_df, fc1_df, fc3_df)\n",
    "    max_val = length(aa) - 1\n",
    "    @inbounds for i in 1:max_val\n",
    "        first, last = aa[i]+1, aa[i+1]\n",
    "        if last - first > 1\n",
    "            decoded = packet[first:last-1]\n",
    "            bb = findall(x -> x == 0x7d, decoded)\n",
    "            for ii in bb\n",
    "                decoded[ii+1] = decoded[ii+1] ⊻ 0x20\n",
    "            end\n",
    "            deleteat!(decoded, bb)\n",
    "\n",
    "            header = decoded[2]\n",
    "            if header == 0x20\n",
    "                process_f20!(decoded, f20_df)\n",
    "            elseif header == 0x21\n",
    "                process_f21!(decoded, f21_df)\n",
    "            elseif header == 0x23\n",
    "                process_f23!(decoded, f23_df)\n",
    "            elseif header == 0x25\n",
    "                process_f25!(decoded, f25_df)\n",
    "            elseif header == 0x26\n",
    "                process_f26!(decoded, f26_df)\n",
    "            elseif header == 0x28\n",
    "                process_f28!(decoded, f28_df)\n",
    "            elseif header == 0x29\n",
    "                process_f29!(decoded, f29_df)\n",
    "            elseif header == 0x80\n",
    "                process_f80!(decoded, f80_df)\n",
    "            elseif header == 0x81\n",
    "                process_f81!(decoded, f81_df)\n",
    "            elseif header == 0x82\n",
    "                process_f82!(decoded, f82_df)\n",
    "            elseif header == 0xc1\n",
    "                process_fc1!(decoded, fc1_df)\n",
    "            elseif header == 0xc3\n",
    "                process_fc3!(decoded, fc3_df)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# Main Program\n",
    "function main()\n",
    "    \n",
    "    infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Bris\\\\BVA\\\\\", filterlist=\"*BVA\")\n",
    "    data = reinterpret(UInt8, read(infil))\n",
    "    \n",
    "    cols = 12\n",
    "    mat = reshape(view(data, :), cols, :)\n",
    "    packet = vcat(collect(Iterators.flatten(zip(mat[10,:], mat[11,:], mat[12,:]))))\n",
    "    aa = findall(x -> x == 0x7e, packet)\n",
    "\n",
    "    f20_df = DataFrame(Date = [], Segments = [], Smax = [])\n",
    "    f21_df = DataFrame(Date = [], Segments = [])\n",
    "    f23_df = DataFrame(Date = [], Segments = [], Match_vector = [], Sample_number = [])\n",
    "    f25_df = DataFrame(Date = [], Segments = [], Hs = [], Ti = [], Te = [], T1 = [], Tz = [], T3 = [], Tc = [], Rp = [], Tp = [], Smax = [], Theta_p = [], Sigma_p = [])\n",
    "    f26_df = DataFrame(Date = [], Hmax = [], Thmax = [], Tmax = [], Htmax = [], Havg = [], Tavg = [], Hsrms = [], Nw = [], Nc = [], Epsilon = [], Coverage = [])\n",
    "    f28_df = DataFrame(Date = [], Segments = [])\n",
    "    f29_df = DataFrame(Date = [], Coverage = [], Nw = [], Epsilon = [], Hmax = [], THmax = [], H10 = [], TH10 = [], H3 = [], TH3 = [], Havg = [], Tavg = [])\n",
    "    f80_df = DataFrame(Date = [], Latitude = [], Longitude = [])\n",
    "    f81_df = DataFrame(Date = [], SST = [])\n",
    "    f82_df = DataFrame(Date = [], Firmware = [], Speed = [], Direction = [], SST = [])\n",
    "    fc1_df = DataFrame(Date = [], Firmware = [], Hatch_uid = [], Hull_uid = [], Uptime = [], Battery_energy = [], Boostcaps_energy = [], Hatch_temp = [], Battery_voltage = [], Batteries_per_section = [], Battery_section_number = [], Initial_battery_energy = [], Ov = [], Cv = [], Ox = [], Oy = [], Cx = [], Cy = [], Mu0 = [], Sigma0 = [], Mui = [], Sigmai = [], Muh = [], Sigmah = [], Cpitch = [], Croll = [], Tensor = [])\n",
    "    fc3_df = DataFrame(Date = [], Battery_life = [])\n",
    "\n",
    "    process_packets(packet, aa, f20_df, f21_df, f23_df, f25_df, f26_df, f28_df, f29_df, f80_df, f81_df, f82_df, fc1_df, fc3_df)\n",
    "\n",
    "    f23_df = unique!(f23_df)\n",
    "    f23_df = get_matches_optimized([join(string.(row, base=16, pad=2)) for row in eachrow(mat[:,1:9])], f23_df)\n",
    "    f23_df = f23_first_row_check_optimized(f23_df)\n",
    "\n",
    "    plot_f29(f29_df)\n",
    "end\n",
    "\n",
    "# Run the main program\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804e591-0650-427c-99d0-995a2c6383b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "\n",
    "function process_f20!(f20_vals, heave_spectrum_df)\n",
    "    #######################################\n",
    "    # Function to calculate parameters from Upcross wave height quantiles message  (0xf20)\n",
    "    # Refer to DWTP (Ver. 16 January 2019) Section 4.8 pp.56-61\n",
    "    \n",
    "    # Get Timestamp in UTC - refer Section 3.2 HF link header pp. 25-26\n",
    "    timestamp = unix2datetime.(parse(Int, bitstring(f20_vals[3])*bitstring(f20_vals[4])*bitstring(f20_vals[5])*bitstring(f20_vals[6]); base=2))\n",
    "    \n",
    "    # Convert time to Australian Eastern Standard Time\n",
    "    timestamp = timestamp + Hour(0)\n",
    "    println(timestamp)\n",
    "\n",
    "    # Get Number of Segments Used\n",
    "    segments = parse(Int, bitstring(f20_vals[9]); base=2)\n",
    "\n",
    "    # Get Smax\n",
    "    smax = 5000 * (exp(parse(Int, bitstring(f20_vals[10]) * bitstring(f20_vals[11])[1:4]; base=2) / 200) - 1) / (exp(4094/200) - 1)\n",
    "    println(smax)\n",
    "    \n",
    "    # Obtain the heave_spectrum from s0 to s99\n",
    "    heave_spectrum = Float64[]\n",
    "    for ii in 12:3:159\n",
    "        try\n",
    "            value1 = (exp(parse(Int, bitstring(f20_vals[ii]) * bitstring(f20_vals[ii+1])[1:4]; base=2) / 200) - 1) / (exp(4094/200) - 1)\n",
    "            value2 = (exp(parse(Int, bitstring(f20_vals[ii+1])[5:8] * bitstring(f20_vals[ii+2]); base=2) / 200) - 1) / (exp(4094/200) - 1)\n",
    "            \n",
    "            push!(heave_spectrum, value1)\n",
    "            push!(heave_spectrum, value2)\n",
    "        catch\n",
    "            # Handle the error: skip, replace with default, or log\n",
    "            # push!(heave_spectrum, 0.0)  # Example: Replace missing with a default value (0.0)\n",
    "            push!(heave_spectrum, missing)\n",
    "            push!(heave_spectrum, missing)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Push a row with timestamp, segments, and Smax to the DataFrame\n",
    "    push!(heave_spectrum_df, (Date=timestamp, Segments=segments, Smax=smax))\n",
    "\n",
    "    return (timestamp, segments, smax, heave_spectrum)\n",
    "end\n",
    "\n",
    "\n",
    "infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Bris\\\\BVA\\\\\", filterlist=\"*BVA\")\n",
    "data = reinterpret(UInt8, read(infil))\n",
    "\n",
    "cols = 12\n",
    "mat = reshape(view(data, :), cols, :)\n",
    "packet = vcat(collect(Iterators.flatten(zip(mat[10,:], mat[11,:], mat[12,:]))))\n",
    "aa = findall(x -> x == 0x7e, packet)\n",
    "\n",
    "f20_df = DataFrame(Date = DateTime[], Segments = Int[], Smax = Float64[])\n",
    "\n",
    "max_val = length(aa) - 1\n",
    "@inbounds for i in 1:max_val\n",
    "    first, last = aa[i]+1, aa[i+1]\n",
    "    if last - first > 1\n",
    "        decoded = packet[first:last-1]\n",
    "        bb = findall(x -> x == 0x7d, decoded)\n",
    "        for ii in bb\n",
    "            decoded[ii+1] = decoded[ii+1] ⊻ 0x20\n",
    "        end\n",
    "        deleteat!(decoded, bb)\n",
    "\n",
    "        header = decoded[2]\n",
    "        if header == 0x20\n",
    "            println(decoded)\n",
    "            process_f20!(decoded, f20_df)\n",
    "        end\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb094eea-60af-4aa9-bfe7-e9ed1fbb88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = unique(f20_df)\n",
    "plot(aa.Date,aa.Smax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b87011-1c64-4219-bacc-c2b3678cecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time begin\n",
    "    \n",
    "    hex_matrix = string.(mat'[:,1:9], base=16, pad=2)\n",
    "   \n",
    "    result_vector = [join(row) for row in eachrow(hex_matrix)]\n",
    "\n",
    "    # Initialize an empty vector to store the split strings\n",
    "    split_vector = String[]\n",
    "    \n",
    "    # Iterate through each string in result_vector and split it in half\n",
    "    for string in result_vector\n",
    "        half_length = div(length(string), 2)\n",
    "        push!(split_vector, string[1:half_length])\n",
    "        push!(split_vector, string[half_length+1:end])\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa75702-ab55-42bb-a066-cd59376e0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 3\n",
    "end_val = f23_df.Data_vector[val]\n",
    "start_val = end_val - div(f23_df.Sample_number[val],2) + 1\n",
    "start_time = f23_df.Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be45ecf-923a-4474-af97-bd2f695af671",
   "metadata": {},
   "source": [
    "### Don't use this - but, keep it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ec7b5-184b-4564-af8b-17ca270a0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(:Data_vector => x -> !(ismissing(x) || isnothing(x) || isnan(x)), first(f23_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3983284-e208-4c34-ab91-ef26c0324820",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_vector = String[]\n",
    "\n",
    "for string in result_vector\n",
    "    half_length = div(length(Data[1]), 2)\n",
    "    push!(split_vector, string[1:half_length])\n",
    "    push!(split_vector, string[half_length+1:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e78505-4ac3-42c6-b042-23a7a9ffc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_matches(Data, f23_df)\n",
    "##################################\n",
    "    \n",
    "    # Create a dictionary to store indices of hex strings in Data\n",
    "    index_dict = Dict{String, Vector{Int}}()\n",
    "    \n",
    "    # Populate the dictionary\n",
    "    for (i, hex_str) in enumerate(Data)\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(index_dict[hex_str], i)\n",
    "        else\n",
    "            index_dict[hex_str] = [i]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Initialize a vector to store indices\n",
    "    matching_indices = []\n",
    "    \n",
    "    # Iterate through each hex string in f23_df and lookup in the dictionary\n",
    "    for hex_str in f23_df.Match_vector\n",
    "        if haskey(index_dict, hex_str)\n",
    "            push!(matching_indices, index_dict[hex_str][1])\n",
    "        else\n",
    "            push!(matching_indices, nothing)  # If no match found, store an empty vector\n",
    "        end\n",
    "    end\n",
    "\n",
    "    f23_df[!,\"Data_vector\"] = matching_indices\n",
    "\n",
    "    return(f23_df)\n",
    "\n",
    "end    # get_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0b1cd-1f32-4668-9e8c-ea1252f26eff",
   "metadata": {},
   "source": [
    "### Write contents of df's to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb73239-b2e7-428f-9fec-3097efefb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "\n",
    "outfil = split(split(infil,\"\\\\\")[3],\".\")[1]\n",
    "df = [f20_df, f21_df, f23_df, f25_df, f26_df, f28_df, f29_df, f80_df, f81_df, f82_df, fc1_df, fc3_df]\n",
    "fx = [\"f20_df\",\"f21_df\",\"f23_df\",\"f25_df\",\"f26_df\",\"f28_df\",\"f29_df\",\"f80_df\",\"f81_df\",\"f82_df\",\"fc1_df\",\"fc3_df\"]\n",
    "\n",
    "for i in 1:length(fx)\n",
    "   \n",
    "    outfil_fx = \".\\\\\"*outfil*\"_\"*fx[i]*\".csv\"\n",
    "    println(outfil_fx)\n",
    "    if fx[i] == \"f23_df\"\n",
    "        replace!(df[i].Data_vector, nothing => -99)\n",
    "    end\n",
    "    CSV.write(outfil_fx, df[i])\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dates, DataFrames, Distributions, DSP\n",
    "using Gtk\n",
    "using LaTeXStrings\n",
    "using NativeFileDialog\n",
    "using Plots, Printf\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "csv_directory = pick_folder()\n",
    "\n",
    "# build list of all csv files in selected directory\n",
    "csv_files = filter(x->occursin(\".csv\",x), readdir(csv_directory));\n",
    "f26_file = csv_files[findfirst(contains(\"{0xF26}\"),csv_files[findall(x->endswith(uppercase(x), \".CSV\"), csv_files)])];\n",
    "\n",
    "\n",
    "\n",
    "p1 = plot(f26_df.Date, f26_df.Hmax, lc=:green, lw=:4, label=\"Hmax\")\n",
    "p1 = plot!(f26_df.Date, f26_df.Thmax, lc=:yellow, lw=:4, label=\"THmax\")    \n",
    "p1 = plot!(f26_df.Date, f26_df.Tmax, lc=:blue, lw=:4, label=\"Tmax\")    \n",
    "p1 = plot!(f26_df.Date, f26_df.Htmax, lc=:pink, lw=:4, label=\"Htmax\") \n",
    "\n",
    "plot(p1,layout=(4,1),size=(1800,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78e2f4-13a3-4edc-be98-11371f9c5b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_hnw(Data,start_val,end_val)\n",
    "######################################## \n",
    "    \n",
    "    # get WSEs for desired 30-minute record\n",
    "    heave = get_displacement(Data[start_val:end_val,:], 1, 3);              \n",
    "    north = get_displacement(Data[start_val:end_val,:], 4, 6);\n",
    "    west = get_displacement(Data[start_val:end_val,:], 7, 9);\n",
    "    \n",
    "    # Check for missing or extra points in data\n",
    "    for wse in [heave, north, west]\n",
    "        \n",
    "        wse_length = length(wse)\n",
    "        \n",
    "        if wse_length > 4608\n",
    "\n",
    "            # truncate if too long\n",
    "            wse = wse[1:4608]\n",
    "            \n",
    "        else\n",
    "\n",
    "            # zero pad if too short (leave it unchanged if right length)\n",
    "            append!(wse,zeros(4608-wse_length))\n",
    "            \n",
    "        end      \n",
    "\n",
    "    end\n",
    "    \n",
    "    return (heave, north, west)\n",
    "    \n",
    "end    # get_hnw()\n",
    "\n",
    "\n",
    "function get_start_end_dates(df1,idx)   \n",
    "    start_date = df1[idx[1],:].Date # <------- NOTE subtracted 30min from start_date to match Waves4 results\n",
    "    segments = df1[idx[1],:].Segments\n",
    "#   match_vector = df1[idx[1],:].Match_vector\n",
    "    sample_nos = df1[idx[1],:].Sample_number\n",
    "    data_vector = df1[idx[1],:].Data_vector\n",
    "    start_val = data_vector - Int(sample_nos/2) + 1\n",
    "    end_val = data_vector\n",
    "    \n",
    "    return(start_date,start_val, end_val)\n",
    "    \n",
    "end    #(get_start_end_dates)\n",
    "\n",
    "\n",
    "function plot_hnw(df1,df2,Data,idx)\n",
    "######################################## \n",
    "\n",
    "    function spike_value(wse)\n",
    "    #####################################    \n",
    "        median_value = median(wse)\n",
    "        std_value = std(wse)\n",
    "        \n",
    "        return(median_value + 3*std_value)\n",
    "        \n",
    "        end    # spike_value()\n",
    "\n",
    "\n",
    "    println(\"Preparing to plot heave, north, and west time series\")\n",
    "    # Extract parameters from F23 df\n",
    "    start_date, start_val, end_val = get_start_end_dates(df1,idx)\n",
    "    println(idx,\" \",start_date, \" \", start_val, \" \", end_val)\n",
    "\n",
    "    # get WSEs for desired 30-minute record\n",
    "    heave, north, west = get_hnw(Data,start_val,end_val)\n",
    "\n",
    "    spike = spike_value(heave)\n",
    "    heave_spikes = findall(i->(i>=spike), abs.(heave));\n",
    "\n",
    "    spike = spike_value(north)\n",
    "    north_spikes = findall(i->(i>=spike), abs.(north));\n",
    "\n",
    "    spike = spike_value(west)\n",
    "    west_spikes = findall(i->(i>=spike), abs.(west));\n",
    "\n",
    "    # time stamp each WSE\n",
    "    points = collect(0:1:length(heave)-1)/2.56\n",
    "    times = []\n",
    "\n",
    "    for i in 1:length(points)\n",
    "        push!(times,unix2datetime(datetime2unix(start_date) + points[i]))\n",
    "    end\n",
    "\n",
    "    # create plots of heave, north, and west\n",
    "    title_string = Dates.format(start_date, \"dd/mm/yyyy HH:MM\")\n",
    "    p1_hnw = Plots.scatter(times[heave_spikes], heave[heave_spikes], label=\"\", markershape=:circle, ms=4, mc=:white, ma=1, msc=:red, msa=0.25, msw=0.5)\n",
    "    p1_hnw = plot!(times,heave, label=\"\", c=\"#4a536b\", lw=0.5, title=title_string, titlefontsize=12) ##last(split(infil,\"\\\\\")))\n",
    "\n",
    "    # get plotting limits\n",
    "    x_lim1 = xlims(p1_hnw)[1]; y_lim1 = ylims(p1_hnw)[1]\n",
    "    x_lim2 = xlims(p1_hnw)[2]; y_lim2 = ylims(p1_hnw)[2]\n",
    "\n",
    "    x_pos = x_lim1 + abs(x_lim2-x_lim1)*0.02\n",
    "    p1_hnw = annotate!(x_pos, y_lim2*1.1, Plots.text(\"Firmwave ver. = \" * df2.Firmware[1], :grey, :left, 7))\n",
    "    x_pos = x_lim1 + abs(x_lim2-x_lim1)*0.13\n",
    "    p1_hnw = annotate!(x_pos, y_lim2*1.1, Plots.text(\"Hatch UID = \" * string(df2.Hatch_uid[1]), :grey, :left, 7))\n",
    "    x_pos = x_lim1 + abs(x_lim2-x_lim1)*0.26\n",
    "    p1_hnw = annotate!(x_pos, y_lim2*1.1, Plots.text(\"Hull UID = \" * string(df2.Hull_uid[1]), :grey, :left, 7))\n",
    "\n",
    "    p2_hnw = Plots.scatter(times[north_spikes], north[north_spikes], label=\"\", markershape=:circle, ms=4, mc=:white, ma=1, msc=:red, msa=0.25, msw=0.5)\n",
    "    p2_hnw = plot!(times,north, label=\"\", c=\"#aed6dc\", lw=0.5)\n",
    "    p3_hnw = Plots.scatter(times[west_spikes], west[west_spikes], label=\"\", markershape=:circle, ms=4, mc=:white, ma=1, msc=:red, msa=0.25, msw=0.5)\n",
    "    p3_hnw = plot!(times,west, label=\"\", c=\"#ff9a8d\", lw=0.5)\n",
    "\n",
    "    hline!(p1_hnw, [0], lw=1, label=\"\")\n",
    "    hline!(p2_hnw, [0], lw=1, label=\"\")\n",
    "    hline!(p3_hnw, [0], lw=1, label=\"\")\n",
    "\n",
    "    # get plotting limits\n",
    "    x_lim1 = xlims(p1_hnw)[1]; y_lim1 = ylims(p1_hnw)[1]\n",
    "    x_lim2 = xlims(p1_hnw)[2]; y_lim2 = ylims(p1_hnw)[2]\n",
    "\n",
    "    tm_tick = range(times[1],times[end],step=Minute(5))\n",
    "    ticks = Dates.format.(tm_tick,\"MM\")\n",
    "\n",
    "    # display plots to screen\n",
    "    plot_wse = Plots.plot(p1_hnw, p2_hnw, p3_hnw, layout = (3, 1), size = (1400, 900), xticks=(tm_tick,ticks),\n",
    "        xlim=(first(times),last(times)),  xtickfontsize=7, ytickfontsize=8,\n",
    "        framestyle = :box,fg_legend=:transparent, legend=:bottomleft,\n",
    "        margin = 1Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1)            \n",
    "\n",
    "    display(plot_wse)\n",
    "\n",
    "    # create a plot file to be saved as a .PNG\n",
    "##    plt_file = first(infil, length(infil)-4)*\"_plot_hnw_\"*Dates.format(start_date, \"yyyy_mm_dd_HHMM\")*\".png\"\n",
    "\n",
    "    # Save plot to file\n",
    "##    savefig(plt_file)\n",
    "##    println(\"Plot file saved as \",plt_file)\n",
    "       \n",
    "end    # plot_hnw()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789ec88",
   "metadata": {},
   "source": [
    "## Select individual records to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc7816-d8df-4bd3-b4ea-96bbcee475ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Tk\n",
    "\n",
    "#f23_df_copy = deepcopy(f23_df)\n",
    "df1 = deepcopy(f23_df)\n",
    "df2 = deepcopy(fc1_df)\n",
    "first_row = first(df1)\n",
    "\n",
    "\n",
    "if ismissing(first_row.Data_vector) || isnothing(first_row.Data_vector) || isnan(first_row.Data_vector)\n",
    "    println(\"Dropping \" * string(df1.Date[1]))\n",
    "    df1 = df1[2:end, :]  # Drop the first row\n",
    "    df2 = df2[2:end,:]\n",
    "end\n",
    "\n",
    "## Plot 30-minute records\n",
    "# create a vector of dates from the F23 df\n",
    "date_vector = Dates.format.(df1.Date, \"yyyy-mm-dd HH:MM:SS\");\n",
    "\n",
    "# add last datetime - it is only a part record\n",
    "#last(f23_df.Date) + Minute(30)\n",
    "#push!(date_vector, (Dates.format.(last(f23_df.Date) + Minute(30), \"yyyy-mm-dd HH:MM:SS\")))\n",
    "\n",
    "w = Toplevel(\"Select Date\", 235, 650)\n",
    "tcl(\"pack\", \"propagate\", w, false)\n",
    "f = Frame(w)\n",
    "pack(f, expand=true, fill=\"both\")\n",
    "\n",
    "f1 = Frame(f)\n",
    "lb = Treeview(f1, date_vector)\n",
    "\n",
    "scrollbars_add(f1, lb)\n",
    "pack(f1,  expand=true, fill=\"both\")\n",
    "\n",
    "tcl(\"ttk::style\", \"configure\", \"TButton\", foreground=\"blue\", font=\"arial 16 bold\")\n",
    "b = Tk.Button(f, \"Ok\")\n",
    "pack(b)\n",
    "\n",
    "println(\"Select a time from the menu!\")\n",
    "flush(stdout)\n",
    "\n",
    "bind(b, \"command\") do path\n",
    "                    \n",
    "    file_choice = get_value(lb)\n",
    "    global idx = Int(findall(x -> x==file_choice[1], date_vector)[1])\n",
    "    println(idx,\" \",date_vector[idx] * \" selected\")\n",
    "    plot_hnw(df1,df2,Data,idx)\n",
    "##    plot_spectra(f23_df,df2,Data,idx)\n",
    "##    plot_2d(f23_df,Data,idx)\n",
    "##    plot_hnw_2d(f23_df,Data,idx)\n",
    "##    plot_3d(f23_df,Data,idx)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a1be9-7f89-4622-822c-193a3b04608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f23_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a413054-77d4-42c4-ba50-3f36c99de8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last(f23_df.Date) + Minute(30)\n",
    "\n",
    "push!(date_vector, (Dates.format.(last(f23_df.Date) + Minute(30), \"yyyy-mm-dd HH:MM:SS\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c8bf8",
   "metadata": {},
   "source": [
    "## Show individual WSE's and zero-crossing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b18a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_list = 44 # <<<=== For testing only\n",
    "\n",
    "start_date, start_val, end_val = get_start_end_dates(f23_df,found_list)\n",
    "    \n",
    "# get WSEs for desired 30-minute record\n",
    "heave, north, west = get_hnw(Data,start_val,end_val);\n",
    "\n",
    "zero_up = []; valid_zero_up = []\n",
    "\n",
    "for i in 2:length(heave)-2\n",
    "    if (heave[i]*heave[i+1] < 0 && heave[i+1] > 0) || (heave[i] == 0 && heave[i-1] < 0 && heave[i+1] > 0)\n",
    "        push!(zero_up,i)\n",
    "    end\n",
    "end\n",
    "\n",
    "med = median(heave)\n",
    "stdev = std(heave)\n",
    "stdev_3 = med + stdev*3\n",
    "\n",
    "wse_point = 1:1:length(heave)\n",
    "wse_1 = plot(wse_point, heave[wse_point], c=:blue, alpha=.5, label = \"WSE's\")\n",
    "wse_1 = scatter!(wse_point, heave[wse_point], c=:white, ms=3, \n",
    "    markerstrokecolor=:blue, alpha=0.5, markerstrokewidth=0.5, label=\"WSE points\")\n",
    "wse_1 = scatter!(zero_up, heave[zero_up], ms=4, c=:lightgreen, \n",
    "    markerstrokecolor=:green, alpha=0.5, series_annotations = text.(zero_up, :bottom, :red, :size, 10), \n",
    "    annotationhalign = :hcenter, label=\"Zero up-cross points\")\n",
    "\n",
    "# Heave Threshold set at 10mm. Refer to Section 9 Wave statistics pp. 9-10 in Datawell Library Manual\n",
    "threshold = 0.1\n",
    "\n",
    "wse_1 = hline!([threshold; threshold], lw=0.2, ls =:dot, c=:red, label=\"Threshold\\n\")\n",
    "wse_1 = hline!([-threshold; -threshold], lw=0.2, ls =:dot, c=:red, label=\"\")\n",
    "\n",
    "##wse_1 = hline!([stdev_3; stdev_3], lw=0.2, ls =:dot, c=:green, label=\"3 sigma\")\n",
    "##wse_1 = hline!([-stdev_3; -stdev_3], lw=0.2, ls =:dot,  c=:green, label=\"\")\n",
    "\n",
    "wse_plot = plot(wse_1, size = (1400, 800),xlim=(0,200), ylim=(-1.5,1.5), framestyle = :box, \n",
    "    fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    margin = 1Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "display(wse_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98921d27",
   "metadata": {},
   "source": [
    "## Identify individual waves and calculate time-domain heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bd69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "\n",
    "valid_zero_up = []\n",
    "i = 1; j = 2\n",
    "\n",
    "while j < length(zero_up)-1\n",
    "    \n",
    "    crest = maximum(heave[zero_up[i]:zero_up[j]])\n",
    "    crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "    trough = minimum(heave[crest_point:zero_up[j]])\n",
    "\n",
    "    # Check that crest higher than threshold AND trough less than threshold - Possible Valid Wave!!\n",
    "    if (crest > threshold) & (trough < -threshold)\n",
    "        crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "        trough_point = crest_point + argmin(heave[crest_point:zero_up[j]]) - 1\n",
    "        \n",
    "        next_crest = maximum(heave[zero_up[j]:zero_up[j+1]])\n",
    "        \n",
    "        # Check that NEXT crest also exceeds threshold (if so then Valid Wave)\n",
    "        if (next_crest > threshold)\n",
    "##            println(\"Crest found at \",crest_point,\" Trough at \",trough_point)\n",
    "            push!(valid_zero_up,(zero_up[i],zero_up[j]));\n",
    "            i = j\n",
    "        end\n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    else \n",
    "        \n",
    "        j = j+1\n",
    "        \n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "# Process last recorded wave\n",
    "i = j\n",
    "j = j+1\n",
    "\n",
    "crest = maximum(heave[zero_up[i]:zero_up[j]])\n",
    "trough = minimum(heave[zero_up[i]:zero_up[j]])\n",
    "\n",
    "if (crest > threshold) & (trough < -threshold)\n",
    "\n",
    "    crest_point = zero_up[i] + argmax(heave[zero_up[i]:zero_up[j]]) - 1\n",
    "    trough_point = crest_point + argmin(heave[crest_point:zero_up[j]]) - 1\n",
    "    push!(valid_zero_up,(zero_up[i],zero_up[j]));\n",
    "\n",
    "end\n",
    "\n",
    "heights = []\n",
    "\n",
    "for i in 1:length(valid_zero_up)\n",
    "    \n",
    "    crest = maximum(heave[valid_zero_up[i][1]:valid_zero_up[i][2]]);\n",
    "    trough = minimum(heave[valid_zero_up[i][1]:valid_zero_up[i][2]]);\n",
    "    push!(heights,crest - trough)\n",
    "##    @printf(\"Wave %d = %2.3f\\n\",i,crest - trough)\n",
    "\n",
    "end \n",
    "\n",
    "# Get time-domain height parameters\n",
    "sorted_heights = sort(heights, rev=true) # sort heights in reverse order heighestwave to lowest wave\n",
    "hmax = maximum(sorted_heights)\n",
    "hs = mean(sorted_heights[1:Int(ceil(length(sorted_heights)/3))])\n",
    "h10 = mean(sorted_heights[1:Int(ceil(length(sorted_heights) / 10))])\n",
    "hmean = mean(sorted_heights)\n",
    "\n",
    "@printf(\"%s; Waves = %3d; Hmean = %4.2fm; Hs = %4.2fm; H10 = %4.2fm; Hmax = %4.2fm\\n\",Dates.format(start_date, \"yyyy-mm-dd HH:MM\"),length(heights), hmean, hs, h10, hmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b6ca2",
   "metadata": {},
   "source": [
    "## Locate the zero-crossing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e0822",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_point = []\n",
    "for i in 1:length(valid_zero_up)\n",
    "    push!(x_point,valid_zero_up[i][1] + abs(heave[valid_zero_up[i][1]]) / (heave[valid_zero_up[i][1]+1] - heave[valid_zero_up[i][1]]))\n",
    "end\n",
    "\n",
    "# Process final zero-crossing point\n",
    "i = length(valid_zero_up)\n",
    "push!(x_point,valid_zero_up[i][2] + abs(heave[valid_zero_up[i][2]]) / (heave[valid_zero_up[i][2]+1] - heave[valid_zero_up[i][2]]))\n",
    "\n",
    "# Do plots\n",
    "wse_1 = plot(wse_point, heave[wse_point], c=:blue, alpha=0.5, label = \"WSE's\")\n",
    "wse_1 = scatter!(wse_point, heave[wse_point], c=:white, ms=3, \n",
    "    markerstrokecolor=:blue, alpha=0.5, markerstrokewidth=0.5,label=\"WSE points\")\n",
    "wse_1 = scatter!(zero_up, heave[zero_up], ms=3, c=:lightgreen, \n",
    "    markerstrokecolor=:lightgreen, series_annotations = text.(zero_up, :bottom, :red, :size, 10), \n",
    "    annotationhalign = :hcenter, label=\"Zero up-cross points\\n\")\n",
    "wse_1 = scatter!(x_point, zeros(length(x_point)), c=:yellow, ms=5, \n",
    "    markerstrokecolor=:yellow, markershape=:diamond, label=\"Zero-crossing points\")\n",
    "\n",
    "# Heave Threshold set at 10mm. Refer to Section 9 Wave statistics pp. 9-10 in Datawell Library Manual\n",
    "threshold = 0.1 \n",
    "\n",
    "wse_1 = hline!([threshold; threshold], lw=0.2, ls =:dot, c=:red, label=\"Threshold (\"*string(threshold)*\")\\n\")\n",
    "wse_1 = hline!([-threshold; -threshold], lw=0.2, ls =:dot, c=:red, label=\"\")\n",
    "\n",
    "wse_plot = plot(wse_1, size = (1400, 800),xlim=(0,200), ylim=(-1.5,1.5), framestyle = :box, \n",
    "    fg_legend=:transparent, bg_legend=:transparent, legend=:topright,\n",
    "    margin = 1Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "display(wse_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73362c96",
   "metadata": {},
   "source": [
    "## Calculate time-domain periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba787034",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frequency = 2.56 # Hertz Mk4\n",
    "periods = []\n",
    "\n",
    "for i in 1:length(x_point)-1\n",
    "    push!(periods,(x_point[i+1]-x_point[i]) / sample_frequency) # wave period in seconds\n",
    "end\n",
    "\n",
    "sorted_periods = sort(periods, rev=true) # sort periods in reverse order longest period to shortest period\n",
    "tmean = mean(sorted_periods)\n",
    "ths = periods[argmin(abs.(heights .- hs))] \n",
    "th10 = periods[argmin(abs.(heights .- h10))]\n",
    "thmax = periods[argmax(heights)]\n",
    "tmax = maximum(sorted_periods)\n",
    "\n",
    "# get Datawell parameters from f29_df\n",
    "row = f29_df[f29_df.Date .== start_date + Minute(30), :]\n",
    "\n",
    "# Print results\n",
    "@printf(\"\\nQGHL values:     \")\n",
    "@printf(\"%s; Waves = %3d; Hmean = %5.2fm; Hs = %5.2fm; H10 = %5.2fm; Hmax = %5.2fm;\",Dates.format(start_date, \"yyyy-mm-dd HH:MM\"),length(heights), hmean, hs, h10, hmax)\n",
    "@printf(\" Tmean = %5.2fs; THs = %5.2fs; TH10 = %5.2fs; THmax = %5.2fs; Tmax = %5.2fs\",tmean,ths,th10,thmax,tmax)\n",
    "\n",
    "@printf(\"\\nDatawell values: \")\n",
    "@printf(\"%s; Waves = %3d; Hmean = %5.2fm; Hs = %5.2fm; H10 = %5.2fm; Hmax = %5.2fm;\",Dates.format(row.Date[1], \"yyyy-mm-dd HH:MM\"),row.Nw[1], row.Havg[1], row.H3[1], row.H10[1], row.Hmax[1])\n",
    "@printf(\" Tmean = %5.2fs; THs = %5.2fs; TH10 = %5.2fs; THmax = %5.2fs\\n\",row.Tavg[1],row.TH3[1],row.TH10[1],row.THmax[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f7c69",
   "metadata": {},
   "source": [
    "## Plot sorted wave heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_string = Dates.format(start_date, \"dd/mm/yyyy HH:MM\")\n",
    "\n",
    "wave_heights = scatter(sorted_heights, label=\"Sorted wave heights \" * string(length(heights)))\n",
    "\n",
    "wave_heights = hline!([hmax; hmax], lw=2, ls =:dot, c=:red, fillrange = 0, fillalpha = 0.015, fillcolor = :red, label=\"Hmax \" * string(round(hmax, digits=2)) * \"m\\n\")\n",
    "wave_heights = hline!([h10; h10], lw=2, ls =:dot, c=:orange, fillrange = 0, fillalpha = 0.02, fillcolor = :orange,label=\"H10 \" * string(round(h10, digits=2)) * \"m\\n\")\n",
    "wave_heights = hline!([hs; hs], lw=2, ls =:dot, c=:yellow, fillrange = 0, fillalpha = 0.04, fillcolor = :yellow, label=\"Hsig \" * string(round(hs, digits=2)) * \"m\\n\")\n",
    "wave_heights = hline!([hmean; hmean], lw=2, ls =:dot, c=:green, fillrange = 0, fillalpha = 0.05, fillcolor = :green, label=\"Hmean \" * string(round(hmean, digits=2)) * \"m\\n\")\n",
    "\n",
    "subplot = Plots.twinx()\n",
    "\n",
    "wave_heights = scatter!(sort(periods),c=:red)\n",
    "\n",
    "wave_heights_plot = plot(wave_heights, layout = (1, 1), size = (1400, 600),xlim=(0,length(heights)*1.015), ylim=(0,hmax*1.01), xlabel=\"Wave number\", ylabel=\"Wave height (m)\",\n",
    "    framestyle = :box, title=title_string, titlefontsize=12, fg_legend=:transparent, bg_legend=:transparent, legend=:bottomleft,\n",
    "    margin = 10Plots.mm, grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)\n",
    "\n",
    "display(wave_heights_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be94bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_heights = scatter(sorted_heights, c=:blue, yguidefontcolor=:blue, \n",
    "    ylim=(0,hmax*1.01), ylabel=\"Wave heights (m)\", label=\"Sorted wave heights \" * string(length(heights)), \n",
    "    gridcolor=:blue, legend=:bottomleft, foreground_color_grid=\"blue\", yforeground_color_text=\"blue\", ytickfonthalign=:left)\n",
    "\n",
    "subplot = Plots.twinx()\n",
    "\n",
    "wave_heights = scatter!(subplot,sort(periods), c=:red, yguidefontcolor=:red, \n",
    "    ylim=(0,maximum(periods)*1.01), ylabel=\"Wave periods (s)\", label=\"Sorted wave periods \" * string(length(periods)),\n",
    "    gridcolor=:red, legend=:bottomright, foreground_color_grid=\"red\", yforeground_color_text=\"red\", ytickfonthalign=:right)\n",
    "\n",
    "wave_heights_plot = plot(wave_heights, layout = (1, 1), size = (1400, 600),\n",
    "    xlim=(0,length(heights)*1.015), xlabel=\"Wave number\",\n",
    "    framestyle = :box, title=title_string, titlefontsize=12, fg_legend=:transparent, bg_legend=:transparent,\n",
    "    bottommargin = 10Plots.mm, leftmargin = 10Plots.mm, rightmargin = 18Plots.mm, \n",
    "    grid=true, gridlinewidth=0.5, gridstyle=:dot, gridalpha=1, show=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Julia program to read a selected .BVA file and display 30-minute time series plots\n",
    "## JW October 2022\n",
    "#using ContinuousWavelets \n",
    "using Dates, DataFrames, Distributions, DSP\n",
    "using NativeFileDialog\n",
    "using Printf\n",
    "#using Suppressor: @suppress\n",
    "#using Wavelets\n",
    "\n",
    "##import Pkg; Pkg.add(\"Suppressor\")\n",
    "## See https://github.com/JuliaIO/Suppressor.jl\n",
    "##using Suppressor: @suppress\n",
    "\n",
    "#include(\"./read_BVA_processing_tools.jl\")\n",
    "#include(\"./read_BVA_plotting_tools.jl\")\n",
    "\n",
    "################################################\n",
    "################################################\n",
    "##           START OF MAIN PROGRAM\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "# Select a HVA daily .CSV file\n",
    "infil = pick_file(\"C:\\\\QGHL\\\\Wave_data\\\\Bris\\\\BVA\\\\\", filterlist=\"*BVA\");\n",
    "println(\"Selected \",infil)\n",
    "\n",
    "#readdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9799579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path where data cards are located\n",
    "path = \"Z:/Monitoring/Instruments/Wave/Deployment Data/Card Data\"\n",
    "aa = readdir(path, join=true);\n",
    "\n",
    "# get the names of the sites in the directory\n",
    "sites = []\n",
    "for i in aa\n",
    "    push!(sites,last(splitpath(i)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789b582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gtk\n",
    "\n",
    "\n",
    "## Allow user to get a 30-minute record and do plots\n",
    "cb = GtkComboBoxText()\n",
    "choices = sites\n",
    "\n",
    "for choice in choices\n",
    "    push!(cb,choice)\n",
    "end\n",
    "\n",
    "set_gtk_property!(cb,:active,1)\n",
    "\n",
    "signal_connect(cb, \"changed\") do widget, others...\n",
    "\n",
    "    # get the active index\n",
    "    idx = get_gtk_property(cb, \"active\", Int) + 2\n",
    "  \n",
    "    # get the active string \n",
    "    str = Gtk.bytestring( GAccessor.active_text(cb) ) \n",
    "    \n",
    "    println(idx)\n",
    "    println(choice[idx])\n",
    "\n",
    "end\n",
    "\n",
    "win = GtkWindow(\"Select Date\",200,200);\n",
    "Gtk.GAccessor.position(win, Gtk.GtkWindowPosition.CENTER);\n",
    "push!(win, cb);\n",
    "showall(win);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fad6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f82_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7caf4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "currents_df = DataFrame([[],[]], [\"v\", \"u\"])\n",
    "for i in 1:nrow(f82_df)\n",
    "    push!(currents_df,[sin(deg2rad(f82_df.Direction[i])) * f82_df.Speed[i],cos(deg2rad(f82_df.Direction[i])) * f82_df.Speed[i]])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(currents_df.v,currents_df.u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate vectors from speed and direction for x-y plotting\n",
    "distance = f82_df.Speed\n",
    "angle = (90 .- f82_df.Direction)\n",
    "angle[np.where(angle< -180)] += 360\n",
    "angle = np.radians(angle)\n",
    "\n",
    "u, v = (distance * np.cos(angle), distance * np.sin(angle))\n",
    "GPS_Currents_df['u'] = u; GPS_Currents_df['v'] = v\n",
    "values = np.hypot(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf02748",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = f82_df.Direction\n",
    "dist = f82_df.Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3c2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(sin.(deg2rad.(angle)).*dist,cos.(deg2rad.(angle)).*dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea3de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
